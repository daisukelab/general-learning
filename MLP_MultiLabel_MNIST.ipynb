{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcliche.notebook import *\n",
    "from dlcliche.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import logging\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVEN, ODD = 10, 11\n",
    "\n",
    "\n",
    "class MultiLabelMNIST(torchvision.datasets.MNIST):\n",
    "    def __init__(self, folder, train, download=False):\n",
    "        super().__init__(folder, train=train, download=download)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = super().__getitem__(index)\n",
    "        label = [0,0,0,0,0, 0,0,0,0,0, 0,0]\n",
    "        # multi label\n",
    "        label[y] = 1 # one of class 0-9\n",
    "        label[ODD if y % 2 == 1 else EVEN] = 1 # odd or even\n",
    "        return x, label\n",
    "\n",
    "\n",
    "org_train = MultiLabelMNIST('data', train=True, download=True)\n",
    "org_test = MultiLabelMNIST('data', train=False)\n",
    "X = org_train.data.view(-1, 28*28).numpy()\n",
    "y = [org_train[i][1] for i in range(len(org_train))]\n",
    "test_X = org_test.data.view(-1, 28*28).numpy()\n",
    "test_y = [org_test[i][1] for i in range(len(org_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchMLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "mAP BCEWithLogitsLoss() 12 <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MLP.torch_mlp_clf:epoch 0001/200: lr: 0.0010000: loss=24.287267 val_mAP=0.9754035 val_loss=10.9644251\n",
      "INFO:MLP.torch_mlp_clf:epoch 0002/200: lr: 0.0010000: loss=9.447199 val_mAP=0.9843268 val_loss=8.5380964\n",
      "INFO:MLP.torch_mlp_clf:epoch 0003/200: lr: 0.0010000: loss=7.213789 val_mAP=0.9879271 val_loss=7.3381443\n",
      "INFO:MLP.torch_mlp_clf:epoch 0004/200: lr: 0.0010000: loss=5.886614 val_mAP=0.9900838 val_loss=6.4805279\n",
      "INFO:MLP.torch_mlp_clf:epoch 0005/200: lr: 0.0010000: loss=5.003161 val_mAP=0.9902492 val_loss=6.3941507\n",
      "INFO:MLP.torch_mlp_clf:epoch 0006/200: lr: 0.0010000: loss=4.348244 val_mAP=0.9916821 val_loss=6.0478668\n",
      "INFO:MLP.torch_mlp_clf:epoch 0007/200: lr: 0.0010000: loss=3.773977 val_mAP=0.9920540 val_loss=5.9201288\n",
      "INFO:MLP.torch_mlp_clf:epoch 0008/200: lr: 0.0010000: loss=3.327906 val_mAP=0.9917956 val_loss=5.9784708\n",
      "INFO:MLP.torch_mlp_clf:epoch 0009/200: lr: 0.0010000: loss=2.977687 val_mAP=0.9912087 val_loss=6.1600981\n",
      "INFO:MLP.torch_mlp_clf:epoch 0010/200: lr: 0.0010000: loss=2.626330 val_mAP=0.9907955 val_loss=6.1228852\n",
      "INFO:MLP.torch_mlp_clf:epoch 0011/200: lr: 0.0010000: loss=2.372304 val_mAP=0.9912740 val_loss=6.1805372\n",
      "INFO:MLP.torch_mlp_clf:epoch 0012/200: lr: 0.0010000: loss=2.119173 val_mAP=0.9911814 val_loss=6.4400039\n",
      "INFO:MLP.torch_mlp_clf:epoch 0013/200: lr: 0.0010000: loss=1.919730 val_mAP=0.9914281 val_loss=6.4155569\n",
      "INFO:MLP.torch_mlp_clf:epoch 0014/200: lr: 0.0010000: loss=1.726696 val_mAP=0.9915457 val_loss=6.7331038\n",
      "INFO:MLP.torch_mlp_clf:epoch 0015/200: lr: 0.0010000: loss=1.557880 val_mAP=0.9913303 val_loss=6.8166008\n",
      "INFO:MLP.torch_mlp_clf:epoch 0016/200: lr: 0.0010000: loss=1.464928 val_mAP=0.9897110 val_loss=7.3694086\n",
      "INFO:MLP.torch_mlp_clf:epoch 0017/200: lr: 0.0010000: loss=1.305782 val_mAP=0.9911285 val_loss=7.4279776\n",
      "INFO:MLP.torch_mlp_clf:Training complete in 0m 9s\n",
      "INFO:MLP.torch_mlp_clf:Best val_mAP@7 = 0.9920539521199566\n",
      "INFO:MLP.torch_mlp_clf:Best val_loss@7 = 5.92012882232666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9918656498154285\n",
      "mAP: 0.9918656498154285\n",
      "0 precision: 0.9975848850647593\n",
      "1 precision: 0.9977354667745668\n",
      "2 precision: 0.9905144917078703\n",
      "3 precision: 0.9917295357466553\n",
      "4 precision: 0.9918822288272158\n",
      "5 precision: 0.9885295689128226\n",
      "6 precision: 0.9952459059907298\n",
      "7 precision: 0.9831979480659762\n",
      "8 precision: 0.9857008053708226\n",
      "9 precision: 0.9871498797419745\n",
      "10 precision: 0.9973152187629448\n",
      "11 precision: 0.9958018628188042\n"
     ]
    }
   ],
   "source": [
    "from MLP.torch_mlp_clf import TorchMLPClassifier\n",
    "\n",
    "clf = TorchMLPClassifier(debug=True)\n",
    "clf.fit(X, y)\n",
    "print(clf.score(test_X, test_y))\n",
    "\n",
    "# mAP\n",
    "preds = clf.predict(test_X, multi_label_n_class=12)\n",
    "print('mAP:', average_precision_score(test_y, preds))\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    print(i, 'precision:', average_precision_score(np.array(test_y)[:, i], preds[:, i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9449"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X, y)\n",
    "clf.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.9474026367800934\n",
      "0 precision: 0.9628405304861388\n",
      "1 precision: 0.9777427576937121\n",
      "2 precision: 0.9368970334509699\n",
      "3 precision: 0.9338057461457567\n",
      "4 precision: 0.93732925778772\n",
      "5 precision: 0.9328777249016199\n",
      "6 precision: 0.9509429714683367\n",
      "7 precision: 0.9358512465490314\n",
      "8 precision: 0.9264177220742398\n",
      "9 precision: 0.9219176843280218\n",
      "10 precision: 0.9751203970268995\n",
      "11 precision: 0.9770885694486754\n"
     ]
    }
   ],
   "source": [
    "# mAP\n",
    "preds = clf.predict(test_X)\n",
    "print('mAP:', average_precision_score(test_y, preds))\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    print(i, 'precision:', average_precision_score(np.array(test_y)[:, i], preds[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
