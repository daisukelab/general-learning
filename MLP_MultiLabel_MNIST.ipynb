{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcliche.notebook import *\n",
    "from dlcliche.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import logging\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVEN, ODD = 10, 11\n",
    "\n",
    "\n",
    "class MultiLabelMNIST(torchvision.datasets.MNIST):\n",
    "    def __init__(self, folder, train, download=False):\n",
    "        super().__init__(folder, train=train, download=download)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = super().__getitem__(index)\n",
    "        label = [0,0,0,0,0, 0,0,0,0,0, 0,0]\n",
    "        # multi label\n",
    "        label[y] = 1 # one of class 0-9\n",
    "        label[ODD if y % 2 == 1 else EVEN] = 1 # odd or even\n",
    "        return x, label\n",
    "\n",
    "\n",
    "org_train = MultiLabelMNIST('data', train=True, download=True)\n",
    "org_test = MultiLabelMNIST('data', train=False)\n",
    "X = org_train.data.view(-1, 28*28).numpy()\n",
    "y = [org_train[i][1] for i in range(len(org_train))]\n",
    "test_X = org_test.data.view(-1, 28*28).numpy()\n",
    "test_y = [org_test[i][1] for i in range(len(org_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchMLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP BCEWithLogitsLoss() 12 <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MLP.torch_mlp_clf:epoch 0001/200: lr: 0.0010000: loss=23.898793 val_mAP=0.9743387 val_loss=11.4035206\n",
      "INFO:MLP.torch_mlp_clf:epoch 0002/200: lr: 0.0010000: loss=9.302782 val_mAP=0.9827138 val_loss=8.8837156\n",
      "INFO:MLP.torch_mlp_clf:epoch 0003/200: lr: 0.0010000: loss=7.141620 val_mAP=0.9858117 val_loss=8.0453949\n",
      "INFO:MLP.torch_mlp_clf:epoch 0004/200: lr: 0.0010000: loss=5.904229 val_mAP=0.9867794 val_loss=7.5763612\n",
      "INFO:MLP.torch_mlp_clf:epoch 0005/200: lr: 0.0010000: loss=5.061893 val_mAP=0.9881098 val_loss=7.1652446\n",
      "INFO:MLP.torch_mlp_clf:epoch 0006/200: lr: 0.0010000: loss=4.349061 val_mAP=0.9891369 val_loss=7.0590873\n",
      "INFO:MLP.torch_mlp_clf:epoch 0007/200: lr: 0.0010000: loss=3.843415 val_mAP=0.9896522 val_loss=6.8731494\n",
      "INFO:MLP.torch_mlp_clf:epoch 0008/200: lr: 0.0010000: loss=3.406519 val_mAP=0.9895869 val_loss=6.9407611\n",
      "INFO:MLP.torch_mlp_clf:epoch 0009/200: lr: 0.0010000: loss=3.019961 val_mAP=0.9896025 val_loss=7.2136879\n",
      "INFO:MLP.torch_mlp_clf:epoch 0010/200: lr: 0.0010000: loss=2.674500 val_mAP=0.9893791 val_loss=7.4781075\n",
      "INFO:MLP.torch_mlp_clf:epoch 0011/200: lr: 0.0010000: loss=2.407790 val_mAP=0.9891256 val_loss=7.5456996\n",
      "INFO:MLP.torch_mlp_clf:epoch 0012/200: lr: 0.0010000: loss=2.171589 val_mAP=0.9889668 val_loss=7.9733195\n",
      "INFO:MLP.torch_mlp_clf:epoch 0013/200: lr: 0.0010000: loss=1.980981 val_mAP=0.9894820 val_loss=8.1694479\n",
      "INFO:MLP.torch_mlp_clf:epoch 0014/200: lr: 0.0010000: loss=1.755033 val_mAP=0.9890120 val_loss=8.4147635\n",
      "INFO:MLP.torch_mlp_clf:epoch 0015/200: lr: 0.0010000: loss=1.627343 val_mAP=0.9886795 val_loss=9.0047512\n",
      "INFO:MLP.torch_mlp_clf:epoch 0016/200: lr: 0.0010000: loss=1.473132 val_mAP=0.9892852 val_loss=9.2299643\n",
      "INFO:MLP.torch_mlp_clf:epoch 0017/200: lr: 0.0010000: loss=1.296741 val_mAP=0.9889411 val_loss=9.6045961\n",
      "INFO:MLP.torch_mlp_clf:Training complete in 0m 9s\n",
      "INFO:MLP.torch_mlp_clf:Best val_mAP@7 = 0.9896522155222979\n",
      "INFO:MLP.torch_mlp_clf:Best val_loss@7 = 6.873149394989014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9915108079556422\n",
      "mAP: 0.9915108079556422\n",
      "0 precision: 0.9966746110183093\n",
      "1 precision: 0.9969378467043686\n",
      "2 precision: 0.9904229548743705\n",
      "3 precision: 0.9898309449015249\n",
      "4 precision: 0.9921293773063857\n",
      "5 precision: 0.9899033986974093\n",
      "6 precision: 0.9890821765696233\n",
      "7 precision: 0.9891251030062236\n",
      "8 precision: 0.9863025050187532\n",
      "9 precision: 0.9836197147277582\n",
      "10 precision: 0.9973361991021246\n",
      "11 precision: 0.9967648635408557\n"
     ]
    }
   ],
   "source": [
    "from MLP.torch_mlp_clf import TorchMLPClassifier\n",
    "\n",
    "clf = TorchMLPClassifier(debug=True)\n",
    "clf.fit(X, y)\n",
    "print(clf.score(test_X, test_y))\n",
    "\n",
    "# mAP\n",
    "preds = clf.predict(test_X, multi_label_n_class=12)\n",
    "print('mAP:', average_precision_score(test_y, preds))\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    print(i, 'precision:', average_precision_score(np.array(test_y)[:, i], preds[:, i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9449"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X, y)\n",
    "clf.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.9474026367800934\n",
      "0 precision: 0.9628405304861388\n",
      "1 precision: 0.9777427576937121\n",
      "2 precision: 0.9368970334509699\n",
      "3 precision: 0.9338057461457567\n",
      "4 precision: 0.93732925778772\n",
      "5 precision: 0.9328777249016199\n",
      "6 precision: 0.9509429714683367\n",
      "7 precision: 0.9358512465490314\n",
      "8 precision: 0.9264177220742398\n",
      "9 precision: 0.9219176843280218\n",
      "10 precision: 0.9751203970268995\n",
      "11 precision: 0.9770885694486754\n"
     ]
    }
   ],
   "source": [
    "# mAP\n",
    "preds = clf.predict(test_X)\n",
    "print('mAP:', average_precision_score(test_y, preds))\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    print(i, 'precision:', average_precision_score(np.array(test_y)[:, i], preds[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
