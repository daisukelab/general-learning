{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcliche.notebook import *\n",
    "from dlcliche.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import logging\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVEN, ODD = 10, 11\n",
    "\n",
    "\n",
    "class MultiLabelMNIST(torchvision.datasets.MNIST):\n",
    "    def __init__(self, folder, train, download=False):\n",
    "        super().__init__(folder, train=train, download=download)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = super().__getitem__(index)\n",
    "        label = [0,0,0,0,0, 0,0,0,0,0, 0,0]\n",
    "        # multi label\n",
    "        label[y] = 1 # one of class 0-9\n",
    "        label[ODD if y % 2 == 1 else EVEN] = 1 # odd or even\n",
    "        return x, label\n",
    "\n",
    "\n",
    "org_train = MultiLabelMNIST('data', train=True, download=True)\n",
    "org_test = MultiLabelMNIST('data', train=False)\n",
    "X = org_train.data.view(-1, 28*28).numpy()\n",
    "y = [org_train[i][1] for i in range(len(org_train))]\n",
    "test_X = org_test.data.view(-1, 28*28).numpy()\n",
    "test_y = [org_test[i][1] for i in range(len(org_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchMLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP BCEWithLogitsLoss() 12 <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MLP.torch_mlp_clf:epoch 0001/200: lr: 0.0010000: loss=23.627385 val_mAP=0.9740124 val_loss=11.4058819\n",
      "INFO:MLP.torch_mlp_clf:epoch 0002/200: lr: 0.0010000: loss=9.406010 val_mAP=0.9819052 val_loss=9.1678877\n",
      "INFO:MLP.torch_mlp_clf:epoch 0003/200: lr: 0.0010000: loss=7.161456 val_mAP=0.9853427 val_loss=8.1329918\n",
      "INFO:MLP.torch_mlp_clf:epoch 0004/200: lr: 0.0010000: loss=5.893633 val_mAP=0.9867779 val_loss=7.6424270\n",
      "INFO:MLP.torch_mlp_clf:epoch 0005/200: lr: 0.0010000: loss=5.006749 val_mAP=0.9889223 val_loss=7.0023370\n",
      "INFO:MLP.torch_mlp_clf:epoch 0006/200: lr: 0.0010000: loss=4.284182 val_mAP=0.9889400 val_loss=6.9350314\n",
      "INFO:MLP.torch_mlp_clf:epoch 0007/200: lr: 0.0010000: loss=3.801258 val_mAP=0.9893770 val_loss=6.8715057\n",
      "INFO:MLP.torch_mlp_clf:epoch 0008/200: lr: 0.0010000: loss=3.342514 val_mAP=0.9889166 val_loss=7.0793004\n",
      "INFO:MLP.torch_mlp_clf:epoch 0009/200: lr: 0.0010000: loss=2.976077 val_mAP=0.9890925 val_loss=7.2710242\n",
      "INFO:MLP.torch_mlp_clf:epoch 0010/200: lr: 0.0010000: loss=2.657205 val_mAP=0.9891644 val_loss=7.2694931\n",
      "INFO:MLP.torch_mlp_clf:epoch 0011/200: lr: 0.0010000: loss=2.382511 val_mAP=0.9896393 val_loss=7.4262657\n",
      "INFO:MLP.torch_mlp_clf:epoch 0012/200: lr: 0.0010000: loss=2.135260 val_mAP=0.9893982 val_loss=7.3515830\n",
      "INFO:MLP.torch_mlp_clf:epoch 0013/200: lr: 0.0010000: loss=1.928616 val_mAP=0.9894621 val_loss=7.6706328\n",
      "INFO:MLP.torch_mlp_clf:epoch 0014/200: lr: 0.0010000: loss=1.728779 val_mAP=0.9894827 val_loss=7.8670602\n",
      "INFO:MLP.torch_mlp_clf:epoch 0015/200: lr: 0.0010000: loss=1.571191 val_mAP=0.9894231 val_loss=8.2972021\n",
      "INFO:MLP.torch_mlp_clf:epoch 0016/200: lr: 0.0010000: loss=1.428819 val_mAP=0.9897834 val_loss=8.2702608\n",
      "INFO:MLP.torch_mlp_clf:epoch 0017/200: lr: 0.0010000: loss=1.283849 val_mAP=0.9884103 val_loss=8.9599571\n",
      "INFO:MLP.torch_mlp_clf:epoch 0018/200: lr: 0.0010000: loss=1.193559 val_mAP=0.9893351 val_loss=9.3562431\n",
      "INFO:MLP.torch_mlp_clf:epoch 0019/200: lr: 0.0010000: loss=1.114937 val_mAP=0.9894270 val_loss=9.4364634\n",
      "INFO:MLP.torch_mlp_clf:epoch 0020/200: lr: 0.0010000: loss=0.944966 val_mAP=0.9895573 val_loss=9.5167742\n",
      "INFO:MLP.torch_mlp_clf:epoch 0021/200: lr: 0.0010000: loss=0.876255 val_mAP=0.9895798 val_loss=9.9525785\n",
      "INFO:MLP.torch_mlp_clf:epoch 0022/200: lr: 0.0010000: loss=0.770855 val_mAP=0.9897296 val_loss=10.2083311\n",
      "INFO:MLP.torch_mlp_clf:epoch 0023/200: lr: 0.0010000: loss=0.683813 val_mAP=0.9888088 val_loss=10.8839216\n",
      "INFO:MLP.torch_mlp_clf:epoch 0024/200: lr: 0.0010000: loss=0.673441 val_mAP=0.9879882 val_loss=11.0988016\n",
      "INFO:MLP.torch_mlp_clf:epoch 0025/200: lr: 0.0010000: loss=0.692773 val_mAP=0.9889385 val_loss=11.5434618\n",
      "INFO:MLP.torch_mlp_clf:epoch 0026/200: lr: 0.0010000: loss=0.604706 val_mAP=0.9889108 val_loss=11.6466494\n",
      "INFO:MLP.torch_mlp_clf:Training complete in 0m 13s\n",
      "INFO:MLP.torch_mlp_clf:Best val_mAP@16 = 0.989783355159207\n",
      "INFO:MLP.torch_mlp_clf:Best val_loss@16 = 8.27026081085205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9910060679663474\n",
      "mAP: 0.9910060679663474\n",
      "0 precision: 0.9974057239126866\n",
      "1 precision: 0.9980386957979234\n",
      "2 precision: 0.990885893298892\n",
      "3 precision: 0.9891309842491051\n",
      "4 precision: 0.9937799826417528\n",
      "5 precision: 0.9844585935491698\n",
      "6 precision: 0.9938719856398166\n",
      "7 precision: 0.9853184030533945\n",
      "8 precision: 0.9820725280985699\n",
      "9 precision: 0.9872555320460162\n",
      "10 precision: 0.9966258949123221\n",
      "11 precision: 0.993228598396521\n"
     ]
    }
   ],
   "source": [
    "from MLP.torch_mlp_clf import TorchMLPClassifier\n",
    "\n",
    "clf = TorchMLPClassifier(debug=True)\n",
    "clf.fit(X, y)\n",
    "print(clf.score(test_X, test_y))\n",
    "\n",
    "# mAP\n",
    "preds = clf.predict(test_X, multi_label_n_class=12)\n",
    "print('mAP:', average_precision_score(test_y, preds))\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    print(i, 'precision:', average_precision_score(np.array(test_y)[:, i], preds[:, i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9449"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "clf = MLPClassifier()\n",
    "clf.fit(X, y)\n",
    "clf.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.9474026367800934\n",
      "0 precision: 0.9628405304861388\n",
      "1 precision: 0.9777427576937121\n",
      "2 precision: 0.9368970334509699\n",
      "3 precision: 0.9338057461457567\n",
      "4 precision: 0.93732925778772\n",
      "5 precision: 0.9328777249016199\n",
      "6 precision: 0.9509429714683367\n",
      "7 precision: 0.9358512465490314\n",
      "8 precision: 0.9264177220742398\n",
      "9 precision: 0.9219176843280218\n",
      "10 precision: 0.9751203970268995\n",
      "11 precision: 0.9770885694486754\n"
     ]
    }
   ],
   "source": [
    "# mAP\n",
    "preds = clf.predict(test_X)\n",
    "print('mAP:', average_precision_score(test_y, preds))\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    print(i, 'precision:', average_precision_score(np.array(test_y)[:, i], preds[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
