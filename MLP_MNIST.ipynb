{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcliche.notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLP.torch_mlp_clf import TorchMLPClassifier\n",
    "import torchvision\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:MLP.torch_mlp_clf:epoch 0001/200: lr: 0.0010000: loss=128.877170 val_acc=0.9391667 val_loss=42.9718208\n",
      "INFO:MLP.torch_mlp_clf:epoch 0002/200: lr: 0.0010000: loss=86.512939 val_acc=0.9478333 val_loss=36.2844963\n",
      "INFO:MLP.torch_mlp_clf:epoch 0003/200: lr: 0.0010000: loss=78.500240 val_acc=0.9523333 val_loss=32.7468681\n",
      "INFO:MLP.torch_mlp_clf:epoch 0004/200: lr: 0.0010000: loss=72.535238 val_acc=0.9563333 val_loss=31.3419209\n",
      "INFO:MLP.torch_mlp_clf:epoch 0005/200: lr: 0.0010000: loss=69.106015 val_acc=0.9606667 val_loss=29.8797207\n",
      "INFO:MLP.torch_mlp_clf:epoch 0006/200: lr: 0.0010000: loss=67.098794 val_acc=0.9611667 val_loss=29.8532677\n",
      "INFO:MLP.torch_mlp_clf:epoch 0007/200: lr: 0.0010000: loss=64.311957 val_acc=0.9630000 val_loss=28.9807701\n",
      "INFO:MLP.torch_mlp_clf:epoch 0008/200: lr: 0.0010000: loss=62.308114 val_acc=0.9626667 val_loss=31.8337135\n",
      "INFO:MLP.torch_mlp_clf:epoch 0009/200: lr: 0.0010000: loss=60.920887 val_acc=0.9651667 val_loss=32.9946518\n",
      "INFO:MLP.torch_mlp_clf:epoch 0010/200: lr: 0.0010000: loss=59.892648 val_acc=0.9673333 val_loss=32.5627213\n",
      "INFO:MLP.torch_mlp_clf:epoch 0011/200: lr: 0.0010000: loss=58.431947 val_acc=0.9658333 val_loss=31.7960167\n",
      "INFO:MLP.torch_mlp_clf:epoch 0012/200: lr: 0.0010000: loss=57.846728 val_acc=0.9663333 val_loss=34.1011391\n",
      "INFO:MLP.torch_mlp_clf:epoch 0013/200: lr: 0.0010000: loss=57.438701 val_acc=0.9661667 val_loss=33.1440048\n",
      "INFO:MLP.torch_mlp_clf:epoch 0014/200: lr: 0.0010000: loss=56.228311 val_acc=0.9675000 val_loss=34.0227814\n",
      "INFO:MLP.torch_mlp_clf:epoch 0015/200: lr: 0.0010000: loss=56.420938 val_acc=0.9676667 val_loss=33.7479439\n",
      "INFO:MLP.torch_mlp_clf:epoch 0016/200: lr: 0.0010000: loss=55.460008 val_acc=0.9675000 val_loss=36.0679741\n",
      "INFO:MLP.torch_mlp_clf:epoch 0017/200: lr: 0.0010000: loss=55.427753 val_acc=0.9666667 val_loss=37.9385185\n",
      "INFO:MLP.torch_mlp_clf:epoch 0018/200: lr: 0.0010000: loss=53.622095 val_acc=0.9673333 val_loss=38.7887154\n",
      "INFO:MLP.torch_mlp_clf:epoch 0019/200: lr: 0.0010000: loss=53.339398 val_acc=0.9676667 val_loss=39.8528862\n",
      "INFO:MLP.torch_mlp_clf:epoch 0020/200: lr: 0.0010000: loss=52.911425 val_acc=0.9665000 val_loss=36.3071747\n",
      "INFO:MLP.torch_mlp_clf:epoch 0021/200: lr: 0.0010000: loss=52.398707 val_acc=0.9678333 val_loss=38.3303604\n",
      "INFO:MLP.torch_mlp_clf:epoch 0022/200: lr: 0.0010000: loss=51.560071 val_acc=0.9686667 val_loss=37.0663414\n",
      "INFO:MLP.torch_mlp_clf:epoch 0023/200: lr: 0.0010000: loss=52.128815 val_acc=0.9668333 val_loss=41.6764374\n",
      "INFO:MLP.torch_mlp_clf:epoch 0024/200: lr: 0.0010000: loss=51.100589 val_acc=0.9663333 val_loss=41.1736946\n",
      "INFO:MLP.torch_mlp_clf:epoch 0025/200: lr: 0.0010000: loss=51.370107 val_acc=0.9665000 val_loss=41.5274963\n",
      "INFO:MLP.torch_mlp_clf:epoch 0026/200: lr: 0.0010000: loss=50.614202 val_acc=0.9695000 val_loss=43.6419830\n",
      "INFO:MLP.torch_mlp_clf:epoch 0027/200: lr: 0.0010000: loss=51.244580 val_acc=0.9670000 val_loss=44.1975632\n",
      "INFO:MLP.torch_mlp_clf:epoch 0028/200: lr: 0.0010000: loss=50.098605 val_acc=0.9698333 val_loss=44.8182793\n",
      "INFO:MLP.torch_mlp_clf:epoch 0029/200: lr: 0.0010000: loss=50.108408 val_acc=0.9673333 val_loss=48.1218872\n",
      "INFO:MLP.torch_mlp_clf:epoch 0030/200: lr: 0.0010000: loss=49.266911 val_acc=0.9683333 val_loss=48.4184456\n",
      "INFO:MLP.torch_mlp_clf:epoch 0031/200: lr: 0.0010000: loss=49.491294 val_acc=0.9680000 val_loss=50.8306046\n",
      "INFO:MLP.torch_mlp_clf:epoch 0032/200: lr: 0.0010000: loss=49.924118 val_acc=0.9678333 val_loss=51.4522400\n",
      "INFO:MLP.torch_mlp_clf:epoch 0033/200: lr: 0.0010000: loss=49.310794 val_acc=0.9675000 val_loss=53.0805779\n",
      "INFO:MLP.torch_mlp_clf:epoch 0034/200: lr: 0.0010000: loss=49.373312 val_acc=0.9693333 val_loss=52.4305153\n",
      "INFO:MLP.torch_mlp_clf:epoch 0035/200: lr: 0.0010000: loss=48.820090 val_acc=0.9688333 val_loss=52.6253929\n",
      "INFO:MLP.torch_mlp_clf:epoch 0036/200: lr: 0.0010000: loss=48.399371 val_acc=0.9663333 val_loss=55.2131271\n",
      "INFO:MLP.torch_mlp_clf:epoch 0037/200: lr: 0.0010000: loss=48.710333 val_acc=0.9670000 val_loss=56.7867355\n",
      "INFO:MLP.torch_mlp_clf:epoch 0038/200: lr: 0.0010000: loss=48.473970 val_acc=0.9673333 val_loss=55.8621864\n",
      "INFO:MLP.torch_mlp_clf:epoch 0039/200: lr: 0.0010000: loss=48.833534 val_acc=0.9676667 val_loss=58.4289703\n",
      "INFO:MLP.torch_mlp_clf:epoch 0040/200: lr: 0.0010000: loss=47.817703 val_acc=0.9663333 val_loss=61.2049484\n",
      "INFO:MLP.torch_mlp_clf:epoch 0041/200: lr: 0.0010000: loss=48.614312 val_acc=0.9690000 val_loss=58.5914917\n",
      "INFO:MLP.torch_mlp_clf:epoch 0042/200: lr: 0.0010000: loss=48.492462 val_acc=0.9690000 val_loss=61.7815666\n",
      "INFO:MLP.torch_mlp_clf:epoch 0043/200: lr: 0.0010000: loss=47.800426 val_acc=0.9683333 val_loss=61.5963936\n",
      "INFO:MLP.torch_mlp_clf:epoch 0044/200: lr: 0.0010000: loss=47.546935 val_acc=0.9673333 val_loss=63.7851143\n",
      "INFO:MLP.torch_mlp_clf:epoch 0045/200: lr: 0.0010000: loss=47.673923 val_acc=0.9676667 val_loss=62.6665649\n",
      "INFO:MLP.torch_mlp_clf:epoch 0046/200: lr: 0.0010000: loss=46.340607 val_acc=0.9686667 val_loss=63.7486954\n",
      "INFO:MLP.torch_mlp_clf:epoch 0047/200: lr: 0.0010000: loss=47.376446 val_acc=0.9683333 val_loss=65.6104813\n",
      "INFO:MLP.torch_mlp_clf:epoch 0048/200: lr: 0.0010000: loss=46.694168 val_acc=0.9666667 val_loss=66.3557739\n",
      "INFO:MLP.torch_mlp_clf:epoch 0049/200: lr: 0.0010000: loss=47.171121 val_acc=0.9660000 val_loss=68.1883011\n",
      "INFO:MLP.torch_mlp_clf:epoch 0050/200: lr: 0.0010000: loss=46.661041 val_acc=0.9691667 val_loss=70.4639435\n",
      "INFO:MLP.torch_mlp_clf:epoch 0051/200: lr: 0.0010000: loss=47.114609 val_acc=0.9678333 val_loss=68.0608521\n",
      "INFO:MLP.torch_mlp_clf:epoch 0052/200: lr: 0.0010000: loss=46.569406 val_acc=0.9688333 val_loss=71.1190338\n",
      "INFO:MLP.torch_mlp_clf:epoch 0053/200: lr: 0.0010000: loss=46.086424 val_acc=0.9681667 val_loss=75.3429184\n",
      "INFO:MLP.torch_mlp_clf:epoch 0054/200: lr: 0.0010000: loss=47.132023 val_acc=0.9676667 val_loss=78.3007736\n",
      "INFO:MLP.torch_mlp_clf:epoch 0055/200: lr: 0.0010000: loss=46.787359 val_acc=0.9668333 val_loss=73.2397385\n",
      "INFO:MLP.torch_mlp_clf:epoch 0056/200: lr: 0.0010000: loss=45.263429 val_acc=0.9645000 val_loss=74.0863953\n",
      "INFO:MLP.torch_mlp_clf:epoch 0057/200: lr: 0.0010000: loss=46.914633 val_acc=0.9688333 val_loss=74.8301926\n",
      "INFO:MLP.torch_mlp_clf:epoch 0058/200: lr: 0.0010000: loss=46.793951 val_acc=0.9660000 val_loss=78.7885666\n",
      "INFO:MLP.torch_mlp_clf:Training complete in 0m 30s\n",
      "INFO:MLP.torch_mlp_clf:Best val_acc@28 = 0.9698333333333333\n",
      "INFO:MLP.torch_mlp_clf:Best val_loss@28 = 44.81827926635742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9734"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_train = torchvision.datasets.MNIST('data', train=True, download=True)\n",
    "org_test = torchvision.datasets.MNIST('data', train=False)\n",
    "X, y = org_train.data.view(-1, 28*28).numpy(), org_train.targets.numpy()\n",
    "test_X, test_y = org_test.data.view(-1, 28*28).numpy(), org_test.targets.numpy()\n",
    "\n",
    "clf = TorchMLPClassifier()\n",
    "clf.fit(X, y)\n",
    "clf.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
