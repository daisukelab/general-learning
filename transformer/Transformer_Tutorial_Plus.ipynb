{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlcliche.notebook import *\n",
    "from dlcliche.image import *\n",
    "from dlcliche.torch_utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        encoder_norm = nn.LayerNorm(nhid)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers, norm=encoder_norm)\n",
    "        self.embedding = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.embedding(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "TEXT = torchtext.data.Field(tokenize=get_tokenizer(\"basic_english\"),\n",
    "                            init_token='<sos>',\n",
    "                            eos_token='<eos>',\n",
    "                            lower=True)\n",
    "train_txt, val_txt, test_txt = torchtext.datasets.WikiText2.splits(TEXT)\n",
    "TEXT.build_vocab(train_txt)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def batchify(data, bsz):\n",
    "    data = TEXT.numericalize([data.examples[0].text])\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_txt, batch_size)\n",
    "val_data = batchify(val_txt, eval_batch_size)\n",
    "test_data = batchify(test_txt, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2981 batches | lr 5.00 | ms/batch 10.75 | loss  8.13 | ppl  3392.76\n",
      "| epoch   1 |   400/ 2981 batches | lr 5.00 | ms/batch 10.49 | loss  6.85 | ppl   941.97\n",
      "| epoch   1 |   600/ 2981 batches | lr 5.00 | ms/batch 10.50 | loss  6.41 | ppl   605.46\n",
      "| epoch   1 |   800/ 2981 batches | lr 5.00 | ms/batch 10.52 | loss  6.25 | ppl   519.53\n",
      "| epoch   1 |  1000/ 2981 batches | lr 5.00 | ms/batch 10.50 | loss  6.13 | ppl   460.33\n",
      "| epoch   1 |  1200/ 2981 batches | lr 5.00 | ms/batch 10.52 | loss  6.10 | ppl   447.37\n",
      "| epoch   1 |  1400/ 2981 batches | lr 5.00 | ms/batch 10.51 | loss  6.05 | ppl   423.94\n",
      "| epoch   1 |  1600/ 2981 batches | lr 5.00 | ms/batch 10.52 | loss  6.05 | ppl   426.11\n",
      "| epoch   1 |  1800/ 2981 batches | lr 5.00 | ms/batch 10.52 | loss  5.97 | ppl   389.66\n",
      "| epoch   1 |  2000/ 2981 batches | lr 5.00 | ms/batch 10.52 | loss  5.97 | ppl   390.18\n",
      "| epoch   1 |  2200/ 2981 batches | lr 5.00 | ms/batch 10.55 | loss  5.86 | ppl   349.64\n",
      "| epoch   1 |  2400/ 2981 batches | lr 5.00 | ms/batch 10.53 | loss  5.90 | ppl   364.13\n",
      "| epoch   1 |  2600/ 2981 batches | lr 5.00 | ms/batch 10.54 | loss  5.90 | ppl   366.84\n",
      "| epoch   1 |  2800/ 2981 batches | lr 5.00 | ms/batch 10.53 | loss  5.81 | ppl   332.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 32.72s | valid loss  5.71 | valid ppl   303.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saved best model at 1\n",
      "| epoch   2 |   200/ 2981 batches | lr 4.51 | ms/batch 10.60 | loss  5.81 | ppl   334.38\n",
      "| epoch   2 |   400/ 2981 batches | lr 4.51 | ms/batch 10.56 | loss  5.78 | ppl   325.15\n",
      "| epoch   2 |   600/ 2981 batches | lr 4.51 | ms/batch 10.57 | loss  5.61 | ppl   274.31\n",
      "| epoch   2 |   800/ 2981 batches | lr 4.51 | ms/batch 10.55 | loss  5.65 | ppl   284.26\n",
      "| epoch   2 |  1000/ 2981 batches | lr 4.51 | ms/batch 10.59 | loss  5.60 | ppl   269.11\n",
      "| epoch   2 |  1200/ 2981 batches | lr 4.51 | ms/batch 10.59 | loss  5.62 | ppl   276.07\n",
      "| epoch   2 |  1400/ 2981 batches | lr 4.51 | ms/batch 10.60 | loss  5.64 | ppl   280.33\n",
      "| epoch   2 |  1600/ 2981 batches | lr 4.51 | ms/batch 10.59 | loss  5.67 | ppl   289.81\n",
      "| epoch   2 |  1800/ 2981 batches | lr 4.51 | ms/batch 10.59 | loss  5.59 | ppl   268.53\n",
      "| epoch   2 |  2000/ 2981 batches | lr 4.51 | ms/batch 10.61 | loss  5.63 | ppl   277.98\n",
      "| epoch   2 |  2200/ 2981 batches | lr 4.51 | ms/batch 10.59 | loss  5.52 | ppl   249.90\n",
      "| epoch   2 |  2400/ 2981 batches | lr 4.51 | ms/batch 10.60 | loss  5.58 | ppl   265.63\n",
      "| epoch   2 |  2600/ 2981 batches | lr 4.51 | ms/batch 10.59 | loss  5.60 | ppl   269.85\n",
      "| epoch   2 |  2800/ 2981 batches | lr 4.51 | ms/batch 10.63 | loss  5.52 | ppl   250.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 32.89s | valid loss  5.63 | valid ppl   278.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saved best model at 2\n",
      "| epoch   3 |   200/ 2981 batches | lr 4.29 | ms/batch 10.68 | loss  5.55 | ppl   258.40\n",
      "| epoch   3 |   400/ 2981 batches | lr 4.29 | ms/batch 10.61 | loss  5.56 | ppl   260.49\n",
      "| epoch   3 |   600/ 2981 batches | lr 4.29 | ms/batch 10.62 | loss  5.37 | ppl   214.42\n",
      "| epoch   3 |   800/ 2981 batches | lr 4.29 | ms/batch 10.63 | loss  5.43 | ppl   229.13\n",
      "| epoch   3 |  1000/ 2981 batches | lr 4.29 | ms/batch 10.63 | loss  5.40 | ppl   220.68\n",
      "| epoch   3 |  1200/ 2981 batches | lr 4.29 | ms/batch 10.64 | loss  5.41 | ppl   223.95\n",
      "| epoch   3 |  1400/ 2981 batches | lr 4.29 | ms/batch 10.63 | loss  5.44 | ppl   229.69\n",
      "| epoch   3 |  1600/ 2981 batches | lr 4.29 | ms/batch 10.64 | loss  5.47 | ppl   237.86\n",
      "| epoch   3 |  1800/ 2981 batches | lr 4.29 | ms/batch 10.63 | loss  5.42 | ppl   226.89\n",
      "| epoch   3 |  2000/ 2981 batches | lr 4.29 | ms/batch 10.63 | loss  5.44 | ppl   231.20\n",
      "| epoch   3 |  2200/ 2981 batches | lr 4.29 | ms/batch 10.65 | loss  5.33 | ppl   205.97\n",
      "| epoch   3 |  2400/ 2981 batches | lr 4.29 | ms/batch 10.64 | loss  5.41 | ppl   222.71\n",
      "| epoch   3 |  2600/ 2981 batches | lr 4.29 | ms/batch 10.65 | loss  5.42 | ppl   226.39\n",
      "| epoch   3 |  2800/ 2981 batches | lr 4.29 | ms/batch 10.64 | loss  5.35 | ppl   211.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 33.03s | valid loss  5.54 | valid ppl   254.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saved best model at 3\n",
      "| epoch   4 |   200/ 2981 batches | lr 4.07 | ms/batch 10.69 | loss  5.39 | ppl   219.83\n",
      "| epoch   4 |   400/ 2981 batches | lr 4.07 | ms/batch 10.65 | loss  5.40 | ppl   221.78\n",
      "| epoch   4 |   600/ 2981 batches | lr 4.07 | ms/batch 10.65 | loss  5.21 | ppl   182.62\n",
      "| epoch   4 |   800/ 2981 batches | lr 4.07 | ms/batch 10.64 | loss  5.27 | ppl   195.31\n",
      "| epoch   4 |  1000/ 2981 batches | lr 4.07 | ms/batch 10.65 | loss  5.24 | ppl   188.09\n",
      "| epoch   4 |  1200/ 2981 batches | lr 4.07 | ms/batch 10.64 | loss  5.27 | ppl   194.20\n",
      "| epoch   4 |  1400/ 2981 batches | lr 4.07 | ms/batch 10.66 | loss  5.30 | ppl   200.53\n",
      "| epoch   4 |  1600/ 2981 batches | lr 4.07 | ms/batch 10.64 | loss  5.34 | ppl   208.82\n",
      "| epoch   4 |  1800/ 2981 batches | lr 4.07 | ms/batch 10.66 | loss  5.28 | ppl   197.24\n",
      "| epoch   4 |  2000/ 2981 batches | lr 4.07 | ms/batch 10.66 | loss  5.30 | ppl   201.33\n",
      "| epoch   4 |  2200/ 2981 batches | lr 4.07 | ms/batch 10.65 | loss  5.18 | ppl   177.72\n",
      "| epoch   4 |  2400/ 2981 batches | lr 4.07 | ms/batch 10.65 | loss  5.26 | ppl   193.28\n",
      "| epoch   4 |  2600/ 2981 batches | lr 4.07 | ms/batch 10.65 | loss  5.28 | ppl   196.36\n",
      "| epoch   4 |  2800/ 2981 batches | lr 4.07 | ms/batch 10.67 | loss  5.21 | ppl   183.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 33.08s | valid loss  5.48 | valid ppl   239.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saved best model at 4\n",
      "| epoch   5 |   200/ 2981 batches | lr 3.87 | ms/batch 10.77 | loss  5.26 | ppl   192.35\n",
      "| epoch   5 |   400/ 2981 batches | lr 3.87 | ms/batch 10.72 | loss  5.28 | ppl   195.55\n",
      "| epoch   5 |   600/ 2981 batches | lr 3.87 | ms/batch 10.74 | loss  5.08 | ppl   161.05\n",
      "| epoch   5 |   800/ 2981 batches | lr 3.87 | ms/batch 10.73 | loss  5.15 | ppl   171.79\n",
      "| epoch   5 |  1000/ 2981 batches | lr 3.87 | ms/batch 10.72 | loss  5.10 | ppl   164.69\n",
      "| epoch   5 |  1200/ 2981 batches | lr 3.87 | ms/batch 10.74 | loss  5.15 | ppl   171.99\n",
      "| epoch   5 |  1400/ 2981 batches | lr 3.87 | ms/batch 10.73 | loss  5.17 | ppl   176.46\n",
      "| epoch   5 |  1600/ 2981 batches | lr 3.87 | ms/batch 10.74 | loss  5.22 | ppl   185.00\n",
      "| epoch   5 |  1800/ 2981 batches | lr 3.87 | ms/batch 10.73 | loss  5.16 | ppl   175.02\n",
      "| epoch   5 |  2000/ 2981 batches | lr 3.87 | ms/batch 10.74 | loss  5.19 | ppl   179.09\n",
      "| epoch   5 |  2200/ 2981 batches | lr 3.87 | ms/batch 10.73 | loss  5.06 | ppl   157.78\n",
      "| epoch   5 |  2400/ 2981 batches | lr 3.87 | ms/batch 10.74 | loss  5.15 | ppl   172.48\n",
      "| epoch   5 |  2600/ 2981 batches | lr 3.87 | ms/batch 10.75 | loss  5.17 | ppl   176.38\n",
      "| epoch   5 |  2800/ 2981 batches | lr 3.87 | ms/batch 10.73 | loss  5.11 | ppl   165.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 33.35s | valid loss  5.50 | valid ppl   245.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   200/ 2981 batches | lr 3.68 | ms/batch 10.79 | loss  5.15 | ppl   171.85\n",
      "| epoch   6 |   400/ 2981 batches | lr 3.68 | ms/batch 10.74 | loss  5.17 | ppl   176.39\n",
      "| epoch   6 |   600/ 2981 batches | lr 3.68 | ms/batch 10.74 | loss  4.98 | ppl   145.01\n",
      "| epoch   6 |   800/ 2981 batches | lr 3.68 | ms/batch 10.74 | loss  5.05 | ppl   155.57\n",
      "| epoch   6 |  1000/ 2981 batches | lr 3.68 | ms/batch 10.74 | loss  5.02 | ppl   150.79\n",
      "| epoch   6 |  1200/ 2981 batches | lr 3.68 | ms/batch 10.74 | loss  5.05 | ppl   156.64\n",
      "| epoch   6 |  1400/ 2981 batches | lr 3.68 | ms/batch 10.75 | loss  5.08 | ppl   161.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |  1600/ 2981 batches | lr 3.68 | ms/batch 10.74 | loss  5.13 | ppl   168.27\n",
      "| epoch   6 |  1800/ 2981 batches | lr 3.68 | ms/batch 10.75 | loss  5.08 | ppl   161.28\n",
      "| epoch   6 |  2000/ 2981 batches | lr 3.68 | ms/batch 10.74 | loss  5.10 | ppl   163.63\n",
      "| epoch   6 |  2200/ 2981 batches | lr 3.68 | ms/batch 10.76 | loss  4.97 | ppl   144.10\n",
      "| epoch   6 |  2400/ 2981 batches | lr 3.68 | ms/batch 10.75 | loss  5.05 | ppl   155.48\n",
      "| epoch   6 |  2600/ 2981 batches | lr 3.68 | ms/batch 10.74 | loss  5.07 | ppl   159.70\n",
      "| epoch   6 |  2800/ 2981 batches | lr 3.68 | ms/batch 10.76 | loss  5.02 | ppl   151.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 33.39s | valid loss  5.41 | valid ppl   223.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saved best model at 6\n",
      "| epoch   7 |   200/ 2981 batches | lr 3.49 | ms/batch 10.81 | loss  5.05 | ppl   156.44\n",
      "| epoch   7 |   400/ 2981 batches | lr 3.49 | ms/batch 10.74 | loss  5.07 | ppl   159.46\n",
      "| epoch   7 |   600/ 2981 batches | lr 3.49 | ms/batch 10.75 | loss  4.89 | ppl   133.14\n",
      "| epoch   7 |   800/ 2981 batches | lr 3.49 | ms/batch 10.75 | loss  4.96 | ppl   142.70\n",
      "| epoch   7 |  1000/ 2981 batches | lr 3.49 | ms/batch 10.76 | loss  4.93 | ppl   138.20\n",
      "| epoch   7 |  1200/ 2981 batches | lr 3.49 | ms/batch 10.74 | loss  4.97 | ppl   143.67\n",
      "| epoch   7 |  1400/ 2981 batches | lr 3.49 | ms/batch 10.74 | loss  4.99 | ppl   147.62\n",
      "| epoch   7 |  1600/ 2981 batches | lr 3.49 | ms/batch 10.75 | loss  5.04 | ppl   153.73\n",
      "| epoch   7 |  1800/ 2981 batches | lr 3.49 | ms/batch 10.74 | loss  5.00 | ppl   148.38\n",
      "| epoch   7 |  2000/ 2981 batches | lr 3.49 | ms/batch 10.76 | loss  5.02 | ppl   151.01\n",
      "| epoch   7 |  2200/ 2981 batches | lr 3.49 | ms/batch 10.74 | loss  4.88 | ppl   131.48\n",
      "| epoch   7 |  2400/ 2981 batches | lr 3.49 | ms/batch 10.76 | loss  4.96 | ppl   142.93\n",
      "| epoch   7 |  2600/ 2981 batches | lr 3.49 | ms/batch 10.74 | loss  4.99 | ppl   146.67\n",
      "| epoch   7 |  2800/ 2981 batches | lr 3.49 | ms/batch 10.75 | loss  4.92 | ppl   137.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 33.40s | valid loss  5.44 | valid ppl   230.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   200/ 2981 batches | lr 3.32 | ms/batch 10.81 | loss  4.97 | ppl   143.53\n",
      "| epoch   8 |   400/ 2981 batches | lr 3.32 | ms/batch 10.75 | loss  4.99 | ppl   147.28\n",
      "| epoch   8 |   600/ 2981 batches | lr 3.32 | ms/batch 10.75 | loss  4.81 | ppl   122.26\n",
      "| epoch   8 |   800/ 2981 batches | lr 3.32 | ms/batch 10.76 | loss  4.87 | ppl   130.18\n",
      "| epoch   8 |  1000/ 2981 batches | lr 3.32 | ms/batch 10.75 | loss  4.85 | ppl   128.09\n",
      "| epoch   8 |  1200/ 2981 batches | lr 3.32 | ms/batch 10.76 | loss  4.89 | ppl   132.76\n",
      "| epoch   8 |  1400/ 2981 batches | lr 3.32 | ms/batch 10.75 | loss  4.91 | ppl   135.84\n",
      "| epoch   8 |  1600/ 2981 batches | lr 3.32 | ms/batch 10.75 | loss  4.96 | ppl   142.47\n",
      "| epoch   8 |  1800/ 2981 batches | lr 3.32 | ms/batch 10.76 | loss  4.92 | ppl   136.58\n",
      "| epoch   8 |  2000/ 2981 batches | lr 3.32 | ms/batch 10.75 | loss  4.93 | ppl   138.53\n",
      "| epoch   8 |  2200/ 2981 batches | lr 3.32 | ms/batch 10.76 | loss  4.80 | ppl   121.41\n",
      "| epoch   8 |  2400/ 2981 batches | lr 3.32 | ms/batch 10.75 | loss  4.89 | ppl   132.34\n",
      "| epoch   8 |  2600/ 2981 batches | lr 3.32 | ms/batch 10.76 | loss  4.91 | ppl   135.48\n",
      "| epoch   8 |  2800/ 2981 batches | lr 3.32 | ms/batch 10.75 | loss  4.85 | ppl   127.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 33.41s | valid loss  5.41 | valid ppl   222.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saved best model at 8\n",
      "| epoch   9 |   200/ 2981 batches | lr 3.15 | ms/batch 10.81 | loss  4.89 | ppl   133.46\n",
      "| epoch   9 |   400/ 2981 batches | lr 3.15 | ms/batch 10.76 | loss  4.92 | ppl   137.64\n",
      "| epoch   9 |   600/ 2981 batches | lr 3.15 | ms/batch 10.74 | loss  4.73 | ppl   113.39\n",
      "| epoch   9 |   800/ 2981 batches | lr 3.15 | ms/batch 10.75 | loss  4.80 | ppl   121.39\n",
      "| epoch   9 |  1000/ 2981 batches | lr 3.15 | ms/batch 10.76 | loss  4.78 | ppl   118.83\n",
      "| epoch   9 |  1200/ 2981 batches | lr 3.15 | ms/batch 10.75 | loss  4.82 | ppl   124.56\n",
      "| epoch   9 |  1400/ 2981 batches | lr 3.15 | ms/batch 10.77 | loss  4.84 | ppl   126.83\n",
      "| epoch   9 |  1600/ 2981 batches | lr 3.15 | ms/batch 10.75 | loss  4.89 | ppl   132.90\n",
      "| epoch   9 |  1800/ 2981 batches | lr 3.15 | ms/batch 10.75 | loss  4.84 | ppl   126.57\n",
      "| epoch   9 |  2000/ 2981 batches | lr 3.15 | ms/batch 10.75 | loss  4.86 | ppl   129.12\n",
      "| epoch   9 |  2200/ 2981 batches | lr 3.15 | ms/batch 10.75 | loss  4.73 | ppl   112.97\n",
      "| epoch   9 |  2400/ 2981 batches | lr 3.15 | ms/batch 10.76 | loss  4.81 | ppl   123.08\n",
      "| epoch   9 |  2600/ 2981 batches | lr 3.15 | ms/batch 10.75 | loss  4.84 | ppl   125.99\n",
      "| epoch   9 |  2800/ 2981 batches | lr 3.15 | ms/batch 10.76 | loss  4.77 | ppl   118.22\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 33.41s | valid loss  5.42 | valid ppl   226.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   200/ 2981 batches | lr 2.99 | ms/batch 10.83 | loss  4.82 | ppl   124.10\n",
      "| epoch  10 |   400/ 2981 batches | lr 2.99 | ms/batch 10.75 | loss  4.84 | ppl   127.08\n",
      "| epoch  10 |   600/ 2981 batches | lr 2.99 | ms/batch 10.79 | loss  4.67 | ppl   106.43\n",
      "| epoch  10 |   800/ 2981 batches | lr 2.99 | ms/batch 10.74 | loss  4.73 | ppl   113.52\n",
      "| epoch  10 |  1000/ 2981 batches | lr 2.99 | ms/batch 10.75 | loss  4.72 | ppl   112.05\n",
      "| epoch  10 |  1200/ 2981 batches | lr 2.99 | ms/batch 10.79 | loss  4.75 | ppl   115.70\n",
      "| epoch  10 |  1400/ 2981 batches | lr 2.99 | ms/batch 10.74 | loss  4.78 | ppl   118.56\n",
      "| epoch  10 |  1600/ 2981 batches | lr 2.99 | ms/batch 10.75 | loss  4.82 | ppl   124.39\n",
      "| epoch  10 |  1800/ 2981 batches | lr 2.99 | ms/batch 10.74 | loss  4.78 | ppl   119.26\n",
      "| epoch  10 |  2000/ 2981 batches | lr 2.99 | ms/batch 10.75 | loss  4.80 | ppl   121.49\n",
      "| epoch  10 |  2200/ 2981 batches | lr 2.99 | ms/batch 10.74 | loss  4.67 | ppl   106.27\n",
      "| epoch  10 |  2400/ 2981 batches | lr 2.99 | ms/batch 10.74 | loss  4.74 | ppl   114.45\n",
      "| epoch  10 |  2600/ 2981 batches | lr 2.99 | ms/batch 10.75 | loss  4.77 | ppl   117.34\n",
      "| epoch  10 |  2800/ 2981 batches | lr 2.99 | ms/batch 10.74 | loss  4.71 | ppl   111.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 33.40s | valid loss  5.44 | valid ppl   230.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |   200/ 2981 batches | lr 2.84 | ms/batch 10.79 | loss  4.76 | ppl   116.31\n",
      "| epoch  11 |   400/ 2981 batches | lr 2.84 | ms/batch 10.75 | loss  4.79 | ppl   119.77\n",
      "| epoch  11 |   600/ 2981 batches | lr 2.84 | ms/batch 10.74 | loss  4.60 | ppl    99.71\n",
      "| epoch  11 |   800/ 2981 batches | lr 2.84 | ms/batch 10.75 | loss  4.67 | ppl   106.35\n",
      "| epoch  11 |  1000/ 2981 batches | lr 2.84 | ms/batch 10.73 | loss  4.66 | ppl   105.29\n",
      "| epoch  11 |  1200/ 2981 batches | lr 2.84 | ms/batch 10.67 | loss  4.69 | ppl   109.27\n",
      "| epoch  11 |  1400/ 2981 batches | lr 2.84 | ms/batch 10.68 | loss  4.71 | ppl   111.29\n",
      "| epoch  11 |  1600/ 2981 batches | lr 2.84 | ms/batch 10.67 | loss  4.75 | ppl   116.11\n",
      "| epoch  11 |  1800/ 2981 batches | lr 2.84 | ms/batch 10.68 | loss  4.72 | ppl   112.31\n",
      "| epoch  11 |  2000/ 2981 batches | lr 2.84 | ms/batch 10.67 | loss  4.74 | ppl   114.31\n",
      "| epoch  11 |  2200/ 2981 batches | lr 2.84 | ms/batch 10.68 | loss  4.60 | ppl    99.63\n",
      "| epoch  11 |  2400/ 2981 batches | lr 2.84 | ms/batch 10.67 | loss  4.68 | ppl   107.46\n",
      "| epoch  11 |  2600/ 2981 batches | lr 2.84 | ms/batch 10.67 | loss  4.71 | ppl   110.85\n",
      "| epoch  11 |  2800/ 2981 batches | lr 2.84 | ms/batch 10.69 | loss  4.64 | ppl   104.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 33.22s | valid loss  5.44 | valid ppl   229.74\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |   200/ 2981 batches | lr 2.70 | ms/batch 10.74 | loss  4.70 | ppl   110.04\n",
      "| epoch  12 |   400/ 2981 batches | lr 2.70 | ms/batch 10.67 | loss  4.73 | ppl   112.86\n",
      "| epoch  12 |   600/ 2981 batches | lr 2.70 | ms/batch 10.68 | loss  4.54 | ppl    94.01\n",
      "| epoch  12 |   800/ 2981 batches | lr 2.70 | ms/batch 10.67 | loss  4.61 | ppl   100.45\n",
      "| epoch  12 |  1000/ 2981 batches | lr 2.70 | ms/batch 10.68 | loss  4.61 | ppl   100.18\n",
      "| epoch  12 |  1200/ 2981 batches | lr 2.70 | ms/batch 10.67 | loss  4.64 | ppl   103.14\n",
      "| epoch  12 |  1400/ 2981 batches | lr 2.70 | ms/batch 10.66 | loss  4.66 | ppl   105.19\n",
      "| epoch  12 |  1600/ 2981 batches | lr 2.70 | ms/batch 10.68 | loss  4.70 | ppl   110.18\n",
      "| epoch  12 |  1800/ 2981 batches | lr 2.70 | ms/batch 10.66 | loss  4.66 | ppl   105.73\n",
      "| epoch  12 |  2000/ 2981 batches | lr 2.70 | ms/batch 10.68 | loss  4.68 | ppl   107.76\n",
      "| epoch  12 |  2200/ 2981 batches | lr 2.70 | ms/batch 10.67 | loss  4.54 | ppl    94.11\n",
      "| epoch  12 |  2400/ 2981 batches | lr 2.70 | ms/batch 10.68 | loss  4.62 | ppl   101.77\n",
      "| epoch  12 |  2600/ 2981 batches | lr 2.70 | ms/batch 10.67 | loss  4.65 | ppl   104.15\n",
      "| epoch  12 |  2800/ 2981 batches | lr 2.70 | ms/batch 10.67 | loss  4.60 | ppl    99.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 33.15s | valid loss  5.43 | valid ppl   228.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |   200/ 2981 batches | lr 2.57 | ms/batch 10.72 | loss  4.64 | ppl   104.00\n",
      "| epoch  13 |   400/ 2981 batches | lr 2.57 | ms/batch 10.68 | loss  4.67 | ppl   107.13\n",
      "| epoch  13 |   600/ 2981 batches | lr 2.57 | ms/batch 10.66 | loss  4.49 | ppl    89.41\n",
      "| epoch  13 |   800/ 2981 batches | lr 2.57 | ms/batch 10.68 | loss  4.56 | ppl    95.45\n",
      "| epoch  13 |  1000/ 2981 batches | lr 2.57 | ms/batch 10.67 | loss  4.56 | ppl    95.46\n",
      "| epoch  13 |  1200/ 2981 batches | lr 2.57 | ms/batch 10.69 | loss  4.59 | ppl    98.90\n",
      "| epoch  13 |  1400/ 2981 batches | lr 2.57 | ms/batch 10.66 | loss  4.61 | ppl   100.00\n",
      "| epoch  13 |  1600/ 2981 batches | lr 2.57 | ms/batch 10.66 | loss  4.65 | ppl   104.74\n",
      "| epoch  13 |  1800/ 2981 batches | lr 2.57 | ms/batch 10.68 | loss  4.61 | ppl   100.89\n",
      "| epoch  13 |  2000/ 2981 batches | lr 2.57 | ms/batch 10.67 | loss  4.63 | ppl   102.90\n",
      "| epoch  13 |  2200/ 2981 batches | lr 2.57 | ms/batch 10.68 | loss  4.50 | ppl    89.64\n",
      "| epoch  13 |  2400/ 2981 batches | lr 2.57 | ms/batch 10.66 | loss  4.57 | ppl    96.08\n",
      "| epoch  13 |  2600/ 2981 batches | lr 2.57 | ms/batch 10.68 | loss  4.59 | ppl    98.78\n",
      "| epoch  13 |  2800/ 2981 batches | lr 2.57 | ms/batch 10.67 | loss  4.55 | ppl    94.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 33.15s | valid loss  5.43 | valid ppl   227.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |   200/ 2981 batches | lr 2.44 | ms/batch 10.72 | loss  4.60 | ppl    99.42\n",
      "| epoch  14 |   400/ 2981 batches | lr 2.44 | ms/batch 10.66 | loss  4.63 | ppl   102.39\n",
      "| epoch  14 |   600/ 2981 batches | lr 2.44 | ms/batch 10.68 | loss  4.45 | ppl    85.73\n",
      "| epoch  14 |   800/ 2981 batches | lr 2.44 | ms/batch 10.67 | loss  4.51 | ppl    91.04\n",
      "| epoch  14 |  1000/ 2981 batches | lr 2.44 | ms/batch 10.68 | loss  4.52 | ppl    91.38\n",
      "| epoch  14 |  1200/ 2981 batches | lr 2.44 | ms/batch 10.67 | loss  4.54 | ppl    93.72\n",
      "| epoch  14 |  1400/ 2981 batches | lr 2.44 | ms/batch 10.68 | loss  4.56 | ppl    95.48\n",
      "| epoch  14 |  1600/ 2981 batches | lr 2.44 | ms/batch 10.67 | loss  4.60 | ppl    99.88\n",
      "| epoch  14 |  1800/ 2981 batches | lr 2.44 | ms/batch 10.67 | loss  4.57 | ppl    96.50\n",
      "| epoch  14 |  2000/ 2981 batches | lr 2.44 | ms/batch 10.69 | loss  4.59 | ppl    98.01\n",
      "| epoch  14 |  2200/ 2981 batches | lr 2.44 | ms/batch 10.67 | loss  4.45 | ppl    85.35\n",
      "| epoch  14 |  2400/ 2981 batches | lr 2.44 | ms/batch 10.68 | loss  4.52 | ppl    92.14\n",
      "| epoch  14 |  2600/ 2981 batches | lr 2.44 | ms/batch 10.67 | loss  4.55 | ppl    94.55\n",
      "| epoch  14 |  2800/ 2981 batches | lr 2.44 | ms/batch 10.69 | loss  4.50 | ppl    89.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 33.15s | valid loss  5.45 | valid ppl   232.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |   200/ 2981 batches | lr 2.32 | ms/batch 10.74 | loss  4.56 | ppl    95.47\n",
      "| epoch  15 |   400/ 2981 batches | lr 2.32 | ms/batch 10.67 | loss  4.58 | ppl    97.82\n",
      "| epoch  15 |   600/ 2981 batches | lr 2.32 | ms/batch 10.69 | loss  4.41 | ppl    82.11\n",
      "| epoch  15 |   800/ 2981 batches | lr 2.32 | ms/batch 10.70 | loss  4.47 | ppl    87.54\n",
      "| epoch  15 |  1000/ 2981 batches | lr 2.32 | ms/batch 10.69 | loss  4.47 | ppl    87.05\n",
      "| epoch  15 |  1200/ 2981 batches | lr 2.32 | ms/batch 10.70 | loss  4.50 | ppl    90.08\n",
      "| epoch  15 |  1400/ 2981 batches | lr 2.32 | ms/batch 10.69 | loss  4.51 | ppl    91.23\n",
      "| epoch  15 |  1600/ 2981 batches | lr 2.32 | ms/batch 10.70 | loss  4.56 | ppl    95.41\n",
      "| epoch  15 |  1800/ 2981 batches | lr 2.32 | ms/batch 10.69 | loss  4.53 | ppl    92.32\n",
      "| epoch  15 |  2000/ 2981 batches | lr 2.32 | ms/batch 10.68 | loss  4.55 | ppl    94.23\n",
      "| epoch  15 |  2200/ 2981 batches | lr 2.32 | ms/batch 10.71 | loss  4.40 | ppl    81.66\n",
      "| epoch  15 |  2400/ 2981 batches | lr 2.32 | ms/batch 10.68 | loss  4.48 | ppl    87.91\n",
      "| epoch  15 |  2600/ 2981 batches | lr 2.32 | ms/batch 10.70 | loss  4.51 | ppl    90.99\n",
      "| epoch  15 |  2800/ 2981 batches | lr 2.32 | ms/batch 10.69 | loss  4.46 | ppl    86.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 33.21s | valid loss  5.47 | valid ppl   237.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |   200/ 2981 batches | lr 2.20 | ms/batch 10.74 | loss  4.51 | ppl    91.26\n",
      "| epoch  16 |   400/ 2981 batches | lr 2.20 | ms/batch 10.71 | loss  4.54 | ppl    93.41\n",
      "| epoch  16 |   600/ 2981 batches | lr 2.20 | ms/batch 10.69 | loss  4.37 | ppl    78.77\n",
      "| epoch  16 |   800/ 2981 batches | lr 2.20 | ms/batch 10.69 | loss  4.43 | ppl    83.66\n",
      "| epoch  16 |  1000/ 2981 batches | lr 2.20 | ms/batch 10.70 | loss  4.42 | ppl    83.47\n",
      "| epoch  16 |  1200/ 2981 batches | lr 2.20 | ms/batch 10.69 | loss  4.46 | ppl    86.39\n",
      "| epoch  16 |  1400/ 2981 batches | lr 2.20 | ms/batch 10.70 | loss  4.47 | ppl    87.45\n",
      "| epoch  16 |  1600/ 2981 batches | lr 2.20 | ms/batch 10.68 | loss  4.52 | ppl    92.03\n",
      "| epoch  16 |  1800/ 2981 batches | lr 2.20 | ms/batch 10.70 | loss  4.48 | ppl    88.45\n",
      "| epoch  16 |  2000/ 2981 batches | lr 2.20 | ms/batch 10.68 | loss  4.51 | ppl    90.55\n",
      "| epoch  16 |  2200/ 2981 batches | lr 2.20 | ms/batch 10.68 | loss  4.36 | ppl    78.57\n",
      "| epoch  16 |  2400/ 2981 batches | lr 2.20 | ms/batch 10.69 | loss  4.43 | ppl    84.01\n",
      "| epoch  16 |  2600/ 2981 batches | lr 2.20 | ms/batch 10.68 | loss  4.47 | ppl    86.98\n",
      "| epoch  16 |  2800/ 2981 batches | lr 2.20 | ms/batch 10.70 | loss  4.42 | ppl    83.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 33.20s | valid loss  5.49 | valid ppl   242.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |   200/ 2981 batches | lr 2.09 | ms/batch 10.76 | loss  4.47 | ppl    87.45\n",
      "| epoch  17 |   400/ 2981 batches | lr 2.09 | ms/batch 10.69 | loss  4.50 | ppl    90.00\n",
      "| epoch  17 |   600/ 2981 batches | lr 2.09 | ms/batch 10.69 | loss  4.33 | ppl    75.99\n",
      "| epoch  17 |   800/ 2981 batches | lr 2.09 | ms/batch 10.68 | loss  4.39 | ppl    80.77\n",
      "| epoch  17 |  1000/ 2981 batches | lr 2.09 | ms/batch 10.68 | loss  4.39 | ppl    81.01\n",
      "| epoch  17 |  1200/ 2981 batches | lr 2.09 | ms/batch 10.70 | loss  4.42 | ppl    83.20\n",
      "| epoch  17 |  1400/ 2981 batches | lr 2.09 | ms/batch 10.69 | loss  4.44 | ppl    84.42\n",
      "| epoch  17 |  1600/ 2981 batches | lr 2.09 | ms/batch 10.70 | loss  4.48 | ppl    88.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  17 |  1800/ 2981 batches | lr 2.09 | ms/batch 10.69 | loss  4.45 | ppl    85.67\n",
      "| epoch  17 |  2000/ 2981 batches | lr 2.09 | ms/batch 10.70 | loss  4.47 | ppl    87.12\n",
      "| epoch  17 |  2200/ 2981 batches | lr 2.09 | ms/batch 10.69 | loss  4.32 | ppl    75.50\n",
      "| epoch  17 |  2400/ 2981 batches | lr 2.09 | ms/batch 10.68 | loss  4.40 | ppl    81.27\n",
      "| epoch  17 |  2600/ 2981 batches | lr 2.09 | ms/batch 10.69 | loss  4.42 | ppl    83.34\n",
      "| epoch  17 |  2800/ 2981 batches | lr 2.09 | ms/batch 10.69 | loss  4.38 | ppl    79.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 33.21s | valid loss  5.47 | valid ppl   236.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |   200/ 2981 batches | lr 1.99 | ms/batch 10.74 | loss  4.44 | ppl    84.36\n",
      "| epoch  18 |   400/ 2981 batches | lr 1.99 | ms/batch 10.70 | loss  4.46 | ppl    86.69\n",
      "| epoch  18 |   600/ 2981 batches | lr 1.99 | ms/batch 10.68 | loss  4.29 | ppl    72.95\n",
      "| epoch  18 |   800/ 2981 batches | lr 1.99 | ms/batch 10.70 | loss  4.35 | ppl    77.56\n",
      "| epoch  18 |  1000/ 2981 batches | lr 1.99 | ms/batch 10.68 | loss  4.36 | ppl    77.92\n",
      "| epoch  18 |  1200/ 2981 batches | lr 1.99 | ms/batch 10.68 | loss  4.39 | ppl    80.36\n",
      "| epoch  18 |  1400/ 2981 batches | lr 1.99 | ms/batch 10.73 | loss  4.40 | ppl    81.27\n",
      "| epoch  18 |  1600/ 2981 batches | lr 1.99 | ms/batch 10.72 | loss  4.45 | ppl    85.45\n",
      "| epoch  18 |  1800/ 2981 batches | lr 1.99 | ms/batch 10.74 | loss  4.42 | ppl    82.91\n",
      "| epoch  18 |  2000/ 2981 batches | lr 1.99 | ms/batch 10.72 | loss  4.43 | ppl    84.09\n",
      "| epoch  18 |  2200/ 2981 batches | lr 1.99 | ms/batch 10.74 | loss  4.29 | ppl    72.98\n",
      "| epoch  18 |  2400/ 2981 batches | lr 1.99 | ms/batch 10.72 | loss  4.36 | ppl    78.15\n",
      "| epoch  18 |  2600/ 2981 batches | lr 1.99 | ms/batch 10.73 | loss  4.38 | ppl    80.15\n",
      "| epoch  18 |  2800/ 2981 batches | lr 1.99 | ms/batch 10.74 | loss  4.34 | ppl    76.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 33.28s | valid loss  5.51 | valid ppl   246.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |   200/ 2981 batches | lr 1.89 | ms/batch 10.79 | loss  4.40 | ppl    81.82\n",
      "| epoch  19 |   400/ 2981 batches | lr 1.89 | ms/batch 10.73 | loss  4.43 | ppl    84.01\n",
      "| epoch  19 |   600/ 2981 batches | lr 1.89 | ms/batch 10.73 | loss  4.26 | ppl    70.79\n",
      "| epoch  19 |   800/ 2981 batches | lr 1.89 | ms/batch 10.72 | loss  4.32 | ppl    75.26\n",
      "| epoch  19 |  1000/ 2981 batches | lr 1.89 | ms/batch 10.75 | loss  4.33 | ppl    75.72\n",
      "| epoch  19 |  1200/ 2981 batches | lr 1.89 | ms/batch 10.72 | loss  4.35 | ppl    77.49\n",
      "| epoch  19 |  1400/ 2981 batches | lr 1.89 | ms/batch 10.72 | loss  4.37 | ppl    78.73\n",
      "| epoch  19 |  1600/ 2981 batches | lr 1.89 | ms/batch 10.74 | loss  4.41 | ppl    82.57\n",
      "| epoch  19 |  1800/ 2981 batches | lr 1.89 | ms/batch 10.73 | loss  4.38 | ppl    79.81\n",
      "| epoch  19 |  2000/ 2981 batches | lr 1.89 | ms/batch 10.74 | loss  4.40 | ppl    81.38\n",
      "| epoch  19 |  2200/ 2981 batches | lr 1.89 | ms/batch 10.73 | loss  4.26 | ppl    70.67\n",
      "| epoch  19 |  2400/ 2981 batches | lr 1.89 | ms/batch 10.74 | loss  4.32 | ppl    75.51\n",
      "| epoch  19 |  2600/ 2981 batches | lr 1.89 | ms/batch 10.73 | loss  4.36 | ppl    78.01\n",
      "| epoch  19 |  2800/ 2981 batches | lr 1.89 | ms/batch 10.73 | loss  4.31 | ppl    74.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 33.34s | valid loss  5.47 | valid ppl   237.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |   200/ 2981 batches | lr 1.79 | ms/batch 10.80 | loss  4.37 | ppl    78.79\n",
      "| epoch  20 |   400/ 2981 batches | lr 1.79 | ms/batch 10.73 | loss  4.40 | ppl    81.21\n",
      "| epoch  20 |   600/ 2981 batches | lr 1.79 | ms/batch 10.73 | loss  4.23 | ppl    68.72\n",
      "| epoch  20 |   800/ 2981 batches | lr 1.79 | ms/batch 10.74 | loss  4.29 | ppl    72.96\n",
      "| epoch  20 |  1000/ 2981 batches | lr 1.79 | ms/batch 10.75 | loss  4.30 | ppl    73.38\n",
      "| epoch  20 |  1200/ 2981 batches | lr 1.79 | ms/batch 10.77 | loss  4.33 | ppl    75.81\n",
      "| epoch  20 |  1400/ 2981 batches | lr 1.79 | ms/batch 10.77 | loss  4.33 | ppl    76.20\n",
      "| epoch  20 |  1600/ 2981 batches | lr 1.79 | ms/batch 10.76 | loss  4.38 | ppl    80.07\n",
      "| epoch  20 |  1800/ 2981 batches | lr 1.79 | ms/batch 10.76 | loss  4.35 | ppl    77.41\n",
      "| epoch  20 |  2000/ 2981 batches | lr 1.79 | ms/batch 10.76 | loss  4.37 | ppl    78.66\n",
      "| epoch  20 |  2200/ 2981 batches | lr 1.79 | ms/batch 10.76 | loss  4.23 | ppl    68.56\n",
      "| epoch  20 |  2400/ 2981 batches | lr 1.79 | ms/batch 10.75 | loss  4.29 | ppl    73.26\n",
      "| epoch  20 |  2600/ 2981 batches | lr 1.79 | ms/batch 10.76 | loss  4.32 | ppl    75.48\n",
      "| epoch  20 |  2800/ 2981 batches | lr 1.79 | ms/batch 10.75 | loss  4.28 | ppl    72.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 33.41s | valid loss  5.52 | valid ppl   249.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |   200/ 2981 batches | lr 1.70 | ms/batch 10.81 | loss  4.34 | ppl    76.74\n",
      "| epoch  21 |   400/ 2981 batches | lr 1.70 | ms/batch 10.77 | loss  4.36 | ppl    78.39\n",
      "| epoch  21 |   600/ 2981 batches | lr 1.70 | ms/batch 10.75 | loss  4.20 | ppl    66.82\n",
      "| epoch  21 |   800/ 2981 batches | lr 1.70 | ms/batch 10.75 | loss  4.26 | ppl    70.99\n",
      "| epoch  21 |  1000/ 2981 batches | lr 1.70 | ms/batch 10.77 | loss  4.26 | ppl    71.15\n",
      "| epoch  21 |  1200/ 2981 batches | lr 1.70 | ms/batch 10.75 | loss  4.30 | ppl    73.37\n",
      "| epoch  21 |  1400/ 2981 batches | lr 1.70 | ms/batch 10.76 | loss  4.30 | ppl    73.84\n",
      "| epoch  21 |  1600/ 2981 batches | lr 1.70 | ms/batch 10.75 | loss  4.35 | ppl    77.67\n",
      "| epoch  21 |  1800/ 2981 batches | lr 1.70 | ms/batch 10.76 | loss  4.32 | ppl    75.18\n",
      "| epoch  21 |  2000/ 2981 batches | lr 1.70 | ms/batch 10.75 | loss  4.33 | ppl    76.25\n",
      "| epoch  21 |  2200/ 2981 batches | lr 1.70 | ms/batch 10.75 | loss  4.20 | ppl    66.37\n",
      "| epoch  21 |  2400/ 2981 batches | lr 1.70 | ms/batch 10.77 | loss  4.26 | ppl    70.64\n",
      "| epoch  21 |  2600/ 2981 batches | lr 1.70 | ms/batch 10.75 | loss  4.29 | ppl    72.93\n",
      "| epoch  21 |  2800/ 2981 batches | lr 1.70 | ms/batch 10.76 | loss  4.25 | ppl    70.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 33.42s | valid loss  5.51 | valid ppl   246.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |   200/ 2981 batches | lr 1.62 | ms/batch 10.81 | loss  4.31 | ppl    74.71\n",
      "| epoch  22 |   400/ 2981 batches | lr 1.62 | ms/batch 10.75 | loss  4.34 | ppl    76.42\n",
      "| epoch  22 |   600/ 2981 batches | lr 1.62 | ms/batch 10.76 | loss  4.17 | ppl    64.80\n",
      "| epoch  22 |   800/ 2981 batches | lr 1.62 | ms/batch 10.75 | loss  4.23 | ppl    69.01\n",
      "| epoch  22 |  1000/ 2981 batches | lr 1.62 | ms/batch 10.75 | loss  4.24 | ppl    69.54\n",
      "| epoch  22 |  1200/ 2981 batches | lr 1.62 | ms/batch 10.77 | loss  4.27 | ppl    71.53\n",
      "| epoch  22 |  1400/ 2981 batches | lr 1.62 | ms/batch 10.76 | loss  4.27 | ppl    71.85\n",
      "| epoch  22 |  1600/ 2981 batches | lr 1.62 | ms/batch 10.77 | loss  4.33 | ppl    75.66\n",
      "| epoch  22 |  1800/ 2981 batches | lr 1.62 | ms/batch 10.75 | loss  4.30 | ppl    73.45\n",
      "| epoch  22 |  2000/ 2981 batches | lr 1.62 | ms/batch 10.77 | loss  4.31 | ppl    74.37\n",
      "| epoch  22 |  2200/ 2981 batches | lr 1.62 | ms/batch 10.76 | loss  4.17 | ppl    64.43\n",
      "| epoch  22 |  2400/ 2981 batches | lr 1.62 | ms/batch 10.75 | loss  4.23 | ppl    69.04\n",
      "| epoch  22 |  2600/ 2981 batches | lr 1.62 | ms/batch 10.74 | loss  4.26 | ppl    71.06\n",
      "| epoch  22 |  2800/ 2981 batches | lr 1.62 | ms/batch 10.72 | loss  4.23 | ppl    68.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 33.40s | valid loss  5.50 | valid ppl   245.06\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  23 |   200/ 2981 batches | lr 1.54 | ms/batch 10.78 | loss  4.29 | ppl    72.72\n",
      "| epoch  23 |   400/ 2981 batches | lr 1.54 | ms/batch 10.73 | loss  4.31 | ppl    74.35\n",
      "| epoch  23 |   600/ 2981 batches | lr 1.54 | ms/batch 10.68 | loss  4.15 | ppl    63.14\n",
      "| epoch  23 |   800/ 2981 batches | lr 1.54 | ms/batch 10.69 | loss  4.21 | ppl    67.39\n",
      "| epoch  23 |  1000/ 2981 batches | lr 1.54 | ms/batch 10.68 | loss  4.22 | ppl    67.96\n",
      "| epoch  23 |  1200/ 2981 batches | lr 1.54 | ms/batch 10.68 | loss  4.24 | ppl    69.51\n",
      "| epoch  23 |  1400/ 2981 batches | lr 1.54 | ms/batch 10.69 | loss  4.25 | ppl    69.87\n",
      "| epoch  23 |  1600/ 2981 batches | lr 1.54 | ms/batch 10.67 | loss  4.30 | ppl    73.53\n",
      "| epoch  23 |  1800/ 2981 batches | lr 1.54 | ms/batch 10.69 | loss  4.27 | ppl    71.36\n",
      "| epoch  23 |  2000/ 2981 batches | lr 1.54 | ms/batch 10.68 | loss  4.29 | ppl    72.79\n",
      "| epoch  23 |  2200/ 2981 batches | lr 1.54 | ms/batch 10.69 | loss  4.14 | ppl    63.08\n",
      "| epoch  23 |  2400/ 2981 batches | lr 1.54 | ms/batch 10.68 | loss  4.21 | ppl    67.15\n",
      "| epoch  23 |  2600/ 2981 batches | lr 1.54 | ms/batch 10.68 | loss  4.24 | ppl    69.18\n",
      "| epoch  23 |  2800/ 2981 batches | lr 1.54 | ms/batch 10.69 | loss  4.20 | ppl    66.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 33.20s | valid loss  5.51 | valid ppl   247.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |   200/ 2981 batches | lr 1.46 | ms/batch 10.75 | loss  4.26 | ppl    70.91\n",
      "| epoch  24 |   400/ 2981 batches | lr 1.46 | ms/batch 10.68 | loss  4.29 | ppl    72.87\n",
      "| epoch  24 |   600/ 2981 batches | lr 1.46 | ms/batch 10.69 | loss  4.12 | ppl    61.69\n",
      "| epoch  24 |   800/ 2981 batches | lr 1.46 | ms/batch 10.68 | loss  4.18 | ppl    65.65\n",
      "| epoch  24 |  1000/ 2981 batches | lr 1.46 | ms/batch 10.78 | loss  4.19 | ppl    66.26\n",
      "| epoch  24 |  1200/ 2981 batches | lr 1.46 | ms/batch 10.77 | loss  4.22 | ppl    68.25\n",
      "| epoch  24 |  1400/ 2981 batches | lr 1.46 | ms/batch 10.76 | loss  4.22 | ppl    68.18\n",
      "| epoch  24 |  1600/ 2981 batches | lr 1.46 | ms/batch 10.81 | loss  4.27 | ppl    71.57\n",
      "| epoch  24 |  1800/ 2981 batches | lr 1.46 | ms/batch 10.76 | loss  4.24 | ppl    69.67\n",
      "| epoch  24 |  2000/ 2981 batches | lr 1.46 | ms/batch 10.80 | loss  4.26 | ppl    70.90\n",
      "| epoch  24 |  2200/ 2981 batches | lr 1.46 | ms/batch 10.77 | loss  4.12 | ppl    61.35\n",
      "| epoch  24 |  2400/ 2981 batches | lr 1.46 | ms/batch 10.80 | loss  4.18 | ppl    65.23\n",
      "| epoch  24 |  2600/ 2981 batches | lr 1.46 | ms/batch 10.76 | loss  4.21 | ppl    67.62\n",
      "| epoch  24 |  2800/ 2981 batches | lr 1.46 | ms/batch 10.76 | loss  4.17 | ppl    64.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 33.41s | valid loss  5.53 | valid ppl   251.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |   200/ 2981 batches | lr 1.39 | ms/batch 10.83 | loss  4.24 | ppl    69.40\n",
      "| epoch  25 |   400/ 2981 batches | lr 1.39 | ms/batch 10.77 | loss  4.26 | ppl    70.97\n",
      "| epoch  25 |   600/ 2981 batches | lr 1.39 | ms/batch 10.76 | loss  4.10 | ppl    60.29\n",
      "| epoch  25 |   800/ 2981 batches | lr 1.39 | ms/batch 10.78 | loss  4.17 | ppl    64.44\n",
      "| epoch  25 |  1000/ 2981 batches | lr 1.39 | ms/batch 10.76 | loss  4.17 | ppl    64.73\n",
      "| epoch  25 |  1200/ 2981 batches | lr 1.39 | ms/batch 10.77 | loss  4.20 | ppl    66.62\n",
      "| epoch  25 |  1400/ 2981 batches | lr 1.39 | ms/batch 10.76 | loss  4.20 | ppl    66.74\n",
      "| epoch  25 |  1600/ 2981 batches | lr 1.39 | ms/batch 10.78 | loss  4.25 | ppl    70.14\n",
      "| epoch  25 |  1800/ 2981 batches | lr 1.39 | ms/batch 10.76 | loss  4.22 | ppl    68.19\n",
      "| epoch  25 |  2000/ 2981 batches | lr 1.39 | ms/batch 10.76 | loss  4.24 | ppl    69.52\n",
      "| epoch  25 |  2200/ 2981 batches | lr 1.39 | ms/batch 10.77 | loss  4.10 | ppl    60.19\n",
      "| epoch  25 |  2400/ 2981 batches | lr 1.39 | ms/batch 10.77 | loss  4.16 | ppl    63.94\n",
      "| epoch  25 |  2600/ 2981 batches | lr 1.39 | ms/batch 10.78 | loss  4.19 | ppl    66.21\n",
      "| epoch  25 |  2800/ 2981 batches | lr 1.39 | ms/batch 10.77 | loss  4.16 | ppl    63.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 33.46s | valid loss  5.53 | valid ppl   251.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |   200/ 2981 batches | lr 1.32 | ms/batch 10.81 | loss  4.22 | ppl    67.84\n",
      "| epoch  26 |   400/ 2981 batches | lr 1.32 | ms/batch 10.77 | loss  4.24 | ppl    69.26\n",
      "| epoch  26 |   600/ 2981 batches | lr 1.32 | ms/batch 10.76 | loss  4.08 | ppl    59.03\n",
      "| epoch  26 |   800/ 2981 batches | lr 1.32 | ms/batch 10.76 | loss  4.14 | ppl    62.63\n",
      "| epoch  26 |  1000/ 2981 batches | lr 1.32 | ms/batch 10.78 | loss  4.15 | ppl    63.72\n",
      "| epoch  26 |  1200/ 2981 batches | lr 1.32 | ms/batch 10.76 | loss  4.18 | ppl    65.28\n",
      "| epoch  26 |  1400/ 2981 batches | lr 1.32 | ms/batch 10.77 | loss  4.17 | ppl    64.97\n",
      "| epoch  26 |  1600/ 2981 batches | lr 1.32 | ms/batch 10.77 | loss  4.23 | ppl    68.70\n",
      "| epoch  26 |  1800/ 2981 batches | lr 1.32 | ms/batch 10.77 | loss  4.20 | ppl    66.87\n",
      "| epoch  26 |  2000/ 2981 batches | lr 1.32 | ms/batch 10.76 | loss  4.22 | ppl    68.00\n",
      "| epoch  26 |  2200/ 2981 batches | lr 1.32 | ms/batch 10.77 | loss  4.07 | ppl    58.69\n",
      "| epoch  26 |  2400/ 2981 batches | lr 1.32 | ms/batch 10.78 | loss  4.13 | ppl    62.42\n",
      "| epoch  26 |  2600/ 2981 batches | lr 1.32 | ms/batch 10.76 | loss  4.17 | ppl    64.68\n",
      "| epoch  26 |  2800/ 2981 batches | lr 1.32 | ms/batch 10.78 | loss  4.14 | ppl    62.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 33.44s | valid loss  5.57 | valid ppl   263.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |   200/ 2981 batches | lr 1.25 | ms/batch 10.83 | loss  4.19 | ppl    66.17\n",
      "| epoch  27 |   400/ 2981 batches | lr 1.25 | ms/batch 10.76 | loss  4.22 | ppl    68.07\n",
      "| epoch  27 |   600/ 2981 batches | lr 1.25 | ms/batch 10.78 | loss  4.05 | ppl    57.55\n",
      "| epoch  27 |   800/ 2981 batches | lr 1.25 | ms/batch 10.77 | loss  4.12 | ppl    61.33\n",
      "| epoch  27 |  1000/ 2981 batches | lr 1.25 | ms/batch 10.76 | loss  4.14 | ppl    62.54\n",
      "| epoch  27 |  1200/ 2981 batches | lr 1.25 | ms/batch 10.77 | loss  4.16 | ppl    63.94\n",
      "| epoch  27 |  1400/ 2981 batches | lr 1.25 | ms/batch 10.76 | loss  4.16 | ppl    63.78\n",
      "| epoch  27 |  1600/ 2981 batches | lr 1.25 | ms/batch 10.75 | loss  4.21 | ppl    67.11\n",
      "| epoch  27 |  1800/ 2981 batches | lr 1.25 | ms/batch 10.73 | loss  4.18 | ppl    65.64\n",
      "| epoch  27 |  2000/ 2981 batches | lr 1.25 | ms/batch 10.74 | loss  4.20 | ppl    66.55\n",
      "| epoch  27 |  2200/ 2981 batches | lr 1.25 | ms/batch 10.73 | loss  4.05 | ppl    57.44\n",
      "| epoch  27 |  2400/ 2981 batches | lr 1.25 | ms/batch 10.73 | loss  4.12 | ppl    61.38\n",
      "| epoch  27 |  2600/ 2981 batches | lr 1.25 | ms/batch 10.74 | loss  4.15 | ppl    63.32\n",
      "| epoch  27 |  2800/ 2981 batches | lr 1.25 | ms/batch 10.73 | loss  4.11 | ppl    61.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 33.39s | valid loss  5.55 | valid ppl   256.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |   200/ 2981 batches | lr 1.19 | ms/batch 10.79 | loss  4.17 | ppl    64.87\n",
      "| epoch  28 |   400/ 2981 batches | lr 1.19 | ms/batch 10.74 | loss  4.20 | ppl    66.79\n",
      "| epoch  28 |   600/ 2981 batches | lr 1.19 | ms/batch 10.70 | loss  4.04 | ppl    56.80\n",
      "| epoch  28 |   800/ 2981 batches | lr 1.19 | ms/batch 10.71 | loss  4.10 | ppl    60.38\n",
      "| epoch  28 |  1000/ 2981 batches | lr 1.19 | ms/batch 10.68 | loss  4.11 | ppl    61.25\n",
      "| epoch  28 |  1200/ 2981 batches | lr 1.19 | ms/batch 10.69 | loss  4.14 | ppl    62.53\n",
      "| epoch  28 |  1400/ 2981 batches | lr 1.19 | ms/batch 10.67 | loss  4.14 | ppl    62.70\n",
      "| epoch  28 |  1600/ 2981 batches | lr 1.19 | ms/batch 10.68 | loss  4.19 | ppl    65.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  28 |  1800/ 2981 batches | lr 1.19 | ms/batch 10.69 | loss  4.16 | ppl    64.34\n",
      "| epoch  28 |  2000/ 2981 batches | lr 1.19 | ms/batch 10.67 | loss  4.18 | ppl    65.27\n",
      "| epoch  28 |  2200/ 2981 batches | lr 1.19 | ms/batch 10.69 | loss  4.04 | ppl    56.62\n",
      "| epoch  28 |  2400/ 2981 batches | lr 1.19 | ms/batch 10.67 | loss  4.10 | ppl    60.16\n",
      "| epoch  28 |  2600/ 2981 batches | lr 1.19 | ms/batch 10.68 | loss  4.13 | ppl    62.07\n",
      "| epoch  28 |  2800/ 2981 batches | lr 1.19 | ms/batch 10.69 | loss  4.10 | ppl    60.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 33.22s | valid loss  5.54 | valid ppl   253.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |   200/ 2981 batches | lr 1.13 | ms/batch 10.78 | loss  4.16 | ppl    63.83\n",
      "| epoch  29 |   400/ 2981 batches | lr 1.13 | ms/batch 10.73 | loss  4.18 | ppl    65.46\n",
      "| epoch  29 |   600/ 2981 batches | lr 1.13 | ms/batch 10.74 | loss  4.02 | ppl    55.74\n",
      "| epoch  29 |   800/ 2981 batches | lr 1.13 | ms/batch 10.73 | loss  4.08 | ppl    59.28\n",
      "| epoch  29 |  1000/ 2981 batches | lr 1.13 | ms/batch 10.74 | loss  4.10 | ppl    60.32\n",
      "| epoch  29 |  1200/ 2981 batches | lr 1.13 | ms/batch 10.73 | loss  4.12 | ppl    61.83\n",
      "| epoch  29 |  1400/ 2981 batches | lr 1.13 | ms/batch 10.74 | loss  4.12 | ppl    61.44\n",
      "| epoch  29 |  1600/ 2981 batches | lr 1.13 | ms/batch 10.73 | loss  4.17 | ppl    64.66\n",
      "| epoch  29 |  1800/ 2981 batches | lr 1.13 | ms/batch 10.73 | loss  4.15 | ppl    63.16\n",
      "| epoch  29 |  2000/ 2981 batches | lr 1.13 | ms/batch 10.74 | loss  4.16 | ppl    64.16\n",
      "| epoch  29 |  2200/ 2981 batches | lr 1.13 | ms/batch 10.72 | loss  4.01 | ppl    55.36\n",
      "| epoch  29 |  2400/ 2981 batches | lr 1.13 | ms/batch 10.75 | loss  4.07 | ppl    58.70\n",
      "| epoch  29 |  2600/ 2981 batches | lr 1.13 | ms/batch 10.72 | loss  4.11 | ppl    60.78\n",
      "| epoch  29 |  2800/ 2981 batches | lr 1.13 | ms/batch 10.73 | loss  4.08 | ppl    59.23\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 33.33s | valid loss  5.57 | valid ppl   263.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |   200/ 2981 batches | lr 1.07 | ms/batch 10.76 | loss  4.14 | ppl    62.92\n",
      "| epoch  30 |   400/ 2981 batches | lr 1.07 | ms/batch 10.70 | loss  4.16 | ppl    64.27\n",
      "| epoch  30 |   600/ 2981 batches | lr 1.07 | ms/batch 10.69 | loss  4.00 | ppl    54.83\n",
      "| epoch  30 |   800/ 2981 batches | lr 1.07 | ms/batch 10.71 | loss  4.07 | ppl    58.33\n",
      "| epoch  30 |  1000/ 2981 batches | lr 1.07 | ms/batch 10.70 | loss  4.08 | ppl    59.24\n",
      "| epoch  30 |  1200/ 2981 batches | lr 1.07 | ms/batch 10.70 | loss  4.11 | ppl    60.71\n",
      "| epoch  30 |  1400/ 2981 batches | lr 1.07 | ms/batch 10.69 | loss  4.10 | ppl    60.57\n",
      "| epoch  30 |  1600/ 2981 batches | lr 1.07 | ms/batch 10.70 | loss  4.15 | ppl    63.57\n",
      "| epoch  30 |  1800/ 2981 batches | lr 1.07 | ms/batch 10.69 | loss  4.13 | ppl    62.09\n",
      "| epoch  30 |  2000/ 2981 batches | lr 1.07 | ms/batch 10.70 | loss  4.15 | ppl    63.57\n",
      "| epoch  30 |  2200/ 2981 batches | lr 1.07 | ms/batch 10.70 | loss  4.00 | ppl    54.52\n",
      "| epoch  30 |  2400/ 2981 batches | lr 1.07 | ms/batch 10.68 | loss  4.06 | ppl    58.05\n",
      "| epoch  30 |  2600/ 2981 batches | lr 1.07 | ms/batch 10.70 | loss  4.09 | ppl    59.86\n",
      "| epoch  30 |  2800/ 2981 batches | lr 1.07 | ms/batch 10.70 | loss  4.06 | ppl    58.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 33.22s | valid loss  5.56 | valid ppl   259.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 |   200/ 2981 batches | lr 1.02 | ms/batch 10.74 | loss  4.12 | ppl    61.82\n",
      "| epoch  31 |   400/ 2981 batches | lr 1.02 | ms/batch 10.70 | loss  4.15 | ppl    63.29\n",
      "| epoch  31 |   600/ 2981 batches | lr 1.02 | ms/batch 10.69 | loss  3.99 | ppl    54.00\n",
      "| epoch  31 |   800/ 2981 batches | lr 1.02 | ms/batch 10.70 | loss  4.05 | ppl    57.54\n",
      "| epoch  31 |  1000/ 2981 batches | lr 1.02 | ms/batch 10.71 | loss  4.07 | ppl    58.40\n",
      "| epoch  31 |  1200/ 2981 batches | lr 1.02 | ms/batch 10.69 | loss  4.09 | ppl    59.82\n",
      "| epoch  31 |  1400/ 2981 batches | lr 1.02 | ms/batch 10.71 | loss  4.09 | ppl    59.67\n",
      "| epoch  31 |  1600/ 2981 batches | lr 1.02 | ms/batch 10.69 | loss  4.14 | ppl    62.92\n",
      "| epoch  31 |  1800/ 2981 batches | lr 1.02 | ms/batch 10.71 | loss  4.11 | ppl    61.25\n",
      "| epoch  31 |  2000/ 2981 batches | lr 1.02 | ms/batch 10.68 | loss  4.13 | ppl    62.40\n",
      "| epoch  31 |  2200/ 2981 batches | lr 1.02 | ms/batch 10.69 | loss  3.98 | ppl    53.76\n",
      "| epoch  31 |  2400/ 2981 batches | lr 1.02 | ms/batch 10.70 | loss  4.04 | ppl    56.84\n",
      "| epoch  31 |  2600/ 2981 batches | lr 1.02 | ms/batch 10.69 | loss  4.08 | ppl    59.01\n",
      "| epoch  31 |  2800/ 2981 batches | lr 1.02 | ms/batch 10.70 | loss  4.05 | ppl    57.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 33.22s | valid loss  5.57 | valid ppl   261.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |   200/ 2981 batches | lr 0.97 | ms/batch 10.76 | loss  4.10 | ppl    60.64\n",
      "| epoch  32 |   400/ 2981 batches | lr 0.97 | ms/batch 10.68 | loss  4.13 | ppl    62.37\n",
      "| epoch  32 |   600/ 2981 batches | lr 0.97 | ms/batch 10.71 | loss  3.98 | ppl    53.30\n",
      "| epoch  32 |   800/ 2981 batches | lr 0.97 | ms/batch 10.69 | loss  4.04 | ppl    56.57\n",
      "| epoch  32 |  1000/ 2981 batches | lr 0.97 | ms/batch 10.69 | loss  4.05 | ppl    57.46\n",
      "| epoch  32 |  1200/ 2981 batches | lr 0.97 | ms/batch 10.70 | loss  4.07 | ppl    58.73\n",
      "| epoch  32 |  1400/ 2981 batches | lr 0.97 | ms/batch 10.69 | loss  4.07 | ppl    58.57\n",
      "| epoch  32 |  1600/ 2981 batches | lr 0.97 | ms/batch 10.70 | loss  4.12 | ppl    61.57\n",
      "| epoch  32 |  1800/ 2981 batches | lr 0.97 | ms/batch 10.69 | loss  4.10 | ppl    60.60\n",
      "| epoch  32 |  2000/ 2981 batches | lr 0.97 | ms/batch 10.71 | loss  4.12 | ppl    61.48\n",
      "| epoch  32 |  2200/ 2981 batches | lr 0.97 | ms/batch 10.69 | loss  3.97 | ppl    53.08\n",
      "| epoch  32 |  2400/ 2981 batches | lr 0.97 | ms/batch 10.69 | loss  4.03 | ppl    56.03\n",
      "| epoch  32 |  2600/ 2981 batches | lr 0.97 | ms/batch 10.70 | loss  4.06 | ppl    58.09\n",
      "| epoch  32 |  2800/ 2981 batches | lr 0.97 | ms/batch 10.70 | loss  4.03 | ppl    56.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 33.22s | valid loss  5.58 | valid ppl   264.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |   200/ 2981 batches | lr 0.92 | ms/batch 10.78 | loss  4.10 | ppl    60.11\n",
      "| epoch  33 |   400/ 2981 batches | lr 0.92 | ms/batch 10.74 | loss  4.12 | ppl    61.46\n",
      "| epoch  33 |   600/ 2981 batches | lr 0.92 | ms/batch 10.74 | loss  3.96 | ppl    52.64\n",
      "| epoch  33 |   800/ 2981 batches | lr 0.92 | ms/batch 10.75 | loss  4.03 | ppl    56.02\n",
      "| epoch  33 |  1000/ 2981 batches | lr 0.92 | ms/batch 10.74 | loss  4.04 | ppl    56.78\n",
      "| epoch  33 |  1200/ 2981 batches | lr 0.92 | ms/batch 10.74 | loss  4.06 | ppl    57.85\n",
      "| epoch  33 |  1400/ 2981 batches | lr 0.92 | ms/batch 10.75 | loss  4.05 | ppl    57.63\n",
      "| epoch  33 |  1600/ 2981 batches | lr 0.92 | ms/batch 10.74 | loss  4.11 | ppl    60.67\n",
      "| epoch  33 |  1800/ 2981 batches | lr 0.92 | ms/batch 10.75 | loss  4.09 | ppl    59.64\n",
      "| epoch  33 |  2000/ 2981 batches | lr 0.92 | ms/batch 10.74 | loss  4.10 | ppl    60.63\n",
      "| epoch  33 |  2200/ 2981 batches | lr 0.92 | ms/batch 10.76 | loss  3.95 | ppl    52.00\n",
      "| epoch  33 |  2400/ 2981 batches | lr 0.92 | ms/batch 10.73 | loss  4.01 | ppl    55.22\n",
      "| epoch  33 |  2600/ 2981 batches | lr 0.92 | ms/batch 10.72 | loss  4.05 | ppl    57.38\n",
      "| epoch  33 |  2800/ 2981 batches | lr 0.92 | ms/batch 10.74 | loss  4.01 | ppl    55.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 33.36s | valid loss  5.58 | valid ppl   264.08\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  34 |   200/ 2981 batches | lr 0.87 | ms/batch 10.80 | loss  4.08 | ppl    59.36\n",
      "| epoch  34 |   400/ 2981 batches | lr 0.87 | ms/batch 10.73 | loss  4.10 | ppl    60.56\n",
      "| epoch  34 |   600/ 2981 batches | lr 0.87 | ms/batch 10.74 | loss  3.95 | ppl    51.96\n",
      "| epoch  34 |   800/ 2981 batches | lr 0.87 | ms/batch 10.72 | loss  4.01 | ppl    55.14\n",
      "| epoch  34 |  1000/ 2981 batches | lr 0.87 | ms/batch 10.74 | loss  4.03 | ppl    56.24\n",
      "| epoch  34 |  1200/ 2981 batches | lr 0.87 | ms/batch 10.72 | loss  4.05 | ppl    57.15\n",
      "| epoch  34 |  1400/ 2981 batches | lr 0.87 | ms/batch 10.72 | loss  4.05 | ppl    57.13\n",
      "| epoch  34 |  1600/ 2981 batches | lr 0.87 | ms/batch 10.74 | loss  4.09 | ppl    60.01\n",
      "| epoch  34 |  1800/ 2981 batches | lr 0.87 | ms/batch 10.73 | loss  4.07 | ppl    58.72\n",
      "| epoch  34 |  2000/ 2981 batches | lr 0.87 | ms/batch 10.74 | loss  4.09 | ppl    59.96\n",
      "| epoch  34 |  2200/ 2981 batches | lr 0.87 | ms/batch 10.72 | loss  3.94 | ppl    51.50\n",
      "| epoch  34 |  2400/ 2981 batches | lr 0.87 | ms/batch 10.74 | loss  4.00 | ppl    54.50\n",
      "| epoch  34 |  2600/ 2981 batches | lr 0.87 | ms/batch 10.73 | loss  4.03 | ppl    56.31\n",
      "| epoch  34 |  2800/ 2981 batches | lr 0.87 | ms/batch 10.72 | loss  4.00 | ppl    54.80\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 33.33s | valid loss  5.59 | valid ppl   267.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |   200/ 2981 batches | lr 0.83 | ms/batch 10.79 | loss  4.07 | ppl    58.49\n",
      "| epoch  35 |   400/ 2981 batches | lr 0.83 | ms/batch 10.73 | loss  4.09 | ppl    59.84\n",
      "| epoch  35 |   600/ 2981 batches | lr 0.83 | ms/batch 10.73 | loss  3.93 | ppl    51.15\n",
      "| epoch  35 |   800/ 2981 batches | lr 0.83 | ms/batch 10.74 | loss  4.00 | ppl    54.52\n",
      "| epoch  35 |  1000/ 2981 batches | lr 0.83 | ms/batch 10.73 | loss  4.02 | ppl    55.60\n",
      "| epoch  35 |  1200/ 2981 batches | lr 0.83 | ms/batch 10.74 | loss  4.04 | ppl    56.69\n",
      "| epoch  35 |  1400/ 2981 batches | lr 0.83 | ms/batch 10.72 | loss  4.03 | ppl    56.41\n",
      "| epoch  35 |  1600/ 2981 batches | lr 0.83 | ms/batch 10.72 | loss  4.08 | ppl    59.25\n",
      "| epoch  35 |  1800/ 2981 batches | lr 0.83 | ms/batch 10.74 | loss  4.06 | ppl    58.19\n",
      "| epoch  35 |  2000/ 2981 batches | lr 0.83 | ms/batch 10.72 | loss  4.08 | ppl    59.12\n",
      "| epoch  35 |  2200/ 2981 batches | lr 0.83 | ms/batch 10.74 | loss  3.94 | ppl    51.16\n",
      "| epoch  35 |  2400/ 2981 batches | lr 0.83 | ms/batch 10.73 | loss  3.99 | ppl    54.10\n",
      "| epoch  35 |  2600/ 2981 batches | lr 0.83 | ms/batch 10.73 | loss  4.02 | ppl    55.90\n",
      "| epoch  35 |  2800/ 2981 batches | lr 0.83 | ms/batch 10.73 | loss  3.99 | ppl    53.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 33.34s | valid loss  5.58 | valid ppl   264.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |   200/ 2981 batches | lr 0.79 | ms/batch 10.78 | loss  4.06 | ppl    57.71\n",
      "| epoch  36 |   400/ 2981 batches | lr 0.79 | ms/batch 10.74 | loss  4.09 | ppl    59.56\n",
      "| epoch  36 |   600/ 2981 batches | lr 0.79 | ms/batch 10.72 | loss  3.92 | ppl    50.60\n",
      "| epoch  36 |   800/ 2981 batches | lr 0.79 | ms/batch 10.73 | loss  3.99 | ppl    53.86\n",
      "| epoch  36 |  1000/ 2981 batches | lr 0.79 | ms/batch 10.74 | loss  4.01 | ppl    55.07\n",
      "| epoch  36 |  1200/ 2981 batches | lr 0.79 | ms/batch 10.72 | loss  4.03 | ppl    56.11\n",
      "| epoch  36 |  1400/ 2981 batches | lr 0.79 | ms/batch 10.74 | loss  4.02 | ppl    55.61\n",
      "| epoch  36 |  1600/ 2981 batches | lr 0.79 | ms/batch 10.72 | loss  4.07 | ppl    58.42\n",
      "| epoch  36 |  1800/ 2981 batches | lr 0.79 | ms/batch 10.73 | loss  4.05 | ppl    57.39\n",
      "| epoch  36 |  2000/ 2981 batches | lr 0.79 | ms/batch 10.74 | loss  4.07 | ppl    58.83\n",
      "| epoch  36 |  2200/ 2981 batches | lr 0.79 | ms/batch 10.72 | loss  3.92 | ppl    50.53\n",
      "| epoch  36 |  2400/ 2981 batches | lr 0.79 | ms/batch 10.74 | loss  3.98 | ppl    53.68\n",
      "| epoch  36 |  2600/ 2981 batches | lr 0.79 | ms/batch 10.72 | loss  4.01 | ppl    55.05\n",
      "| epoch  36 |  2800/ 2981 batches | lr 0.79 | ms/batch 10.73 | loss  3.98 | ppl    53.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 33.33s | valid loss  5.60 | valid ppl   270.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |   200/ 2981 batches | lr 0.75 | ms/batch 10.79 | loss  4.04 | ppl    56.96\n",
      "| epoch  37 |   400/ 2981 batches | lr 0.75 | ms/batch 10.73 | loss  4.07 | ppl    58.52\n",
      "| epoch  37 |   600/ 2981 batches | lr 0.75 | ms/batch 10.74 | loss  3.91 | ppl    50.13\n",
      "| epoch  37 |   800/ 2981 batches | lr 0.75 | ms/batch 10.73 | loss  3.97 | ppl    53.18\n",
      "| epoch  37 |  1000/ 2981 batches | lr 0.75 | ms/batch 10.73 | loss  4.00 | ppl    54.52\n",
      "| epoch  37 |  1200/ 2981 batches | lr 0.75 | ms/batch 10.74 | loss  4.01 | ppl    55.41\n",
      "| epoch  37 |  1400/ 2981 batches | lr 0.75 | ms/batch 10.73 | loss  4.01 | ppl    55.31\n",
      "| epoch  37 |  1600/ 2981 batches | lr 0.75 | ms/batch 10.74 | loss  4.06 | ppl    58.08\n",
      "| epoch  37 |  1800/ 2981 batches | lr 0.75 | ms/batch 10.73 | loss  4.04 | ppl    56.79\n",
      "| epoch  37 |  2000/ 2981 batches | lr 0.75 | ms/batch 10.75 | loss  4.06 | ppl    57.88\n",
      "| epoch  37 |  2200/ 2981 batches | lr 0.75 | ms/batch 10.73 | loss  3.91 | ppl    49.88\n",
      "| epoch  37 |  2400/ 2981 batches | lr 0.75 | ms/batch 10.73 | loss  3.97 | ppl    52.75\n",
      "| epoch  37 |  2600/ 2981 batches | lr 0.75 | ms/batch 10.74 | loss  4.00 | ppl    54.64\n",
      "| epoch  37 |  2800/ 2981 batches | lr 0.75 | ms/batch 10.73 | loss  3.97 | ppl    53.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 33.34s | valid loss  5.61 | valid ppl   272.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |   200/ 2981 batches | lr 0.71 | ms/batch 10.78 | loss  4.03 | ppl    56.43\n",
      "| epoch  38 |   400/ 2981 batches | lr 0.71 | ms/batch 10.73 | loss  4.06 | ppl    57.88\n",
      "| epoch  38 |   600/ 2981 batches | lr 0.71 | ms/batch 10.73 | loss  3.91 | ppl    49.70\n",
      "| epoch  38 |   800/ 2981 batches | lr 0.71 | ms/batch 10.75 | loss  3.97 | ppl    52.83\n",
      "| epoch  38 |  1000/ 2981 batches | lr 0.71 | ms/batch 10.72 | loss  3.99 | ppl    53.89\n",
      "| epoch  38 |  1200/ 2981 batches | lr 0.71 | ms/batch 10.73 | loss  4.01 | ppl    55.00\n",
      "| epoch  38 |  1400/ 2981 batches | lr 0.71 | ms/batch 10.74 | loss  4.00 | ppl    54.82\n",
      "| epoch  38 |  1600/ 2981 batches | lr 0.71 | ms/batch 10.73 | loss  4.04 | ppl    56.92\n",
      "| epoch  38 |  1800/ 2981 batches | lr 0.71 | ms/batch 10.74 | loss  4.03 | ppl    56.47\n",
      "| epoch  38 |  2000/ 2981 batches | lr 0.71 | ms/batch 10.73 | loss  4.05 | ppl    57.29\n",
      "| epoch  38 |  2200/ 2981 batches | lr 0.71 | ms/batch 10.74 | loss  3.90 | ppl    49.28\n",
      "| epoch  38 |  2400/ 2981 batches | lr 0.71 | ms/batch 10.73 | loss  3.96 | ppl    52.34\n",
      "| epoch  38 |  2600/ 2981 batches | lr 0.71 | ms/batch 10.73 | loss  3.99 | ppl    54.02\n",
      "| epoch  38 |  2800/ 2981 batches | lr 0.71 | ms/batch 10.74 | loss  3.96 | ppl    52.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 33.32s | valid loss  5.60 | valid ppl   271.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |   200/ 2981 batches | lr 0.68 | ms/batch 10.76 | loss  4.03 | ppl    56.03\n",
      "| epoch  39 |   400/ 2981 batches | lr 0.68 | ms/batch 10.70 | loss  4.05 | ppl    57.62\n",
      "| epoch  39 |   600/ 2981 batches | lr 0.68 | ms/batch 10.71 | loss  3.90 | ppl    49.16\n",
      "| epoch  39 |   800/ 2981 batches | lr 0.68 | ms/batch 10.70 | loss  3.96 | ppl    52.33\n",
      "| epoch  39 |  1000/ 2981 batches | lr 0.68 | ms/batch 10.72 | loss  3.97 | ppl    53.15\n",
      "| epoch  39 |  1200/ 2981 batches | lr 0.68 | ms/batch 10.69 | loss  4.00 | ppl    54.36\n",
      "| epoch  39 |  1400/ 2981 batches | lr 0.68 | ms/batch 10.70 | loss  3.99 | ppl    54.21\n",
      "| epoch  39 |  1600/ 2981 batches | lr 0.68 | ms/batch 10.71 | loss  4.04 | ppl    56.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  39 |  1800/ 2981 batches | lr 0.68 | ms/batch 10.69 | loss  4.02 | ppl    55.83\n",
      "| epoch  39 |  2000/ 2981 batches | lr 0.68 | ms/batch 10.70 | loss  4.04 | ppl    56.89\n",
      "| epoch  39 |  2200/ 2981 batches | lr 0.68 | ms/batch 10.69 | loss  3.89 | ppl    48.97\n",
      "| epoch  39 |  2400/ 2981 batches | lr 0.68 | ms/batch 10.70 | loss  3.95 | ppl    51.80\n",
      "| epoch  39 |  2600/ 2981 batches | lr 0.68 | ms/batch 10.69 | loss  3.98 | ppl    53.63\n",
      "| epoch  39 |  2800/ 2981 batches | lr 0.68 | ms/batch 10.70 | loss  3.95 | ppl    51.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 33.23s | valid loss  5.59 | valid ppl   268.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |   200/ 2981 batches | lr 0.64 | ms/batch 10.75 | loss  4.01 | ppl    55.27\n",
      "| epoch  40 |   400/ 2981 batches | lr 0.64 | ms/batch 10.71 | loss  4.04 | ppl    57.01\n",
      "| epoch  40 |   600/ 2981 batches | lr 0.64 | ms/batch 10.69 | loss  3.89 | ppl    48.76\n",
      "| epoch  40 |   800/ 2981 batches | lr 0.64 | ms/batch 10.71 | loss  3.95 | ppl    51.95\n",
      "| epoch  40 |  1000/ 2981 batches | lr 0.64 | ms/batch 10.69 | loss  3.97 | ppl    52.86\n",
      "| epoch  40 |  1200/ 2981 batches | lr 0.64 | ms/batch 10.71 | loss  3.99 | ppl    53.86\n",
      "| epoch  40 |  1400/ 2981 batches | lr 0.64 | ms/batch 10.69 | loss  3.98 | ppl    53.66\n",
      "| epoch  40 |  1600/ 2981 batches | lr 0.64 | ms/batch 10.69 | loss  4.03 | ppl    56.43\n",
      "| epoch  40 |  1800/ 2981 batches | lr 0.64 | ms/batch 10.70 | loss  4.01 | ppl    55.35\n",
      "| epoch  40 |  2000/ 2981 batches | lr 0.64 | ms/batch 10.70 | loss  4.03 | ppl    56.48\n",
      "| epoch  40 |  2200/ 2981 batches | lr 0.64 | ms/batch 10.70 | loss  3.88 | ppl    48.46\n",
      "| epoch  40 |  2400/ 2981 batches | lr 0.64 | ms/batch 10.69 | loss  3.94 | ppl    51.35\n",
      "| epoch  40 |  2600/ 2981 batches | lr 0.64 | ms/batch 10.71 | loss  3.97 | ppl    53.16\n",
      "| epoch  40 |  2800/ 2981 batches | lr 0.64 | ms/batch 10.69 | loss  3.94 | ppl    51.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 33.23s | valid loss  5.60 | valid ppl   269.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 |   200/ 2981 batches | lr 0.61 | ms/batch 10.74 | loss  4.01 | ppl    54.96\n",
      "| epoch  41 |   400/ 2981 batches | lr 0.61 | ms/batch 10.69 | loss  4.03 | ppl    56.36\n",
      "| epoch  41 |   600/ 2981 batches | lr 0.61 | ms/batch 10.70 | loss  3.88 | ppl    48.28\n",
      "| epoch  41 |   800/ 2981 batches | lr 0.61 | ms/batch 10.69 | loss  3.94 | ppl    51.42\n",
      "| epoch  41 |  1000/ 2981 batches | lr 0.61 | ms/batch 10.71 | loss  3.96 | ppl    52.54\n",
      "| epoch  41 |  1200/ 2981 batches | lr 0.61 | ms/batch 10.70 | loss  3.98 | ppl    53.40\n",
      "| epoch  41 |  1400/ 2981 batches | lr 0.61 | ms/batch 10.70 | loss  3.98 | ppl    53.36\n",
      "| epoch  41 |  1600/ 2981 batches | lr 0.61 | ms/batch 10.69 | loss  4.02 | ppl    55.72\n",
      "| epoch  41 |  1800/ 2981 batches | lr 0.61 | ms/batch 10.69 | loss  4.00 | ppl    54.79\n",
      "| epoch  41 |  2000/ 2981 batches | lr 0.61 | ms/batch 10.71 | loss  4.02 | ppl    55.71\n",
      "| epoch  41 |  2200/ 2981 batches | lr 0.61 | ms/batch 10.69 | loss  3.87 | ppl    47.95\n",
      "| epoch  41 |  2400/ 2981 batches | lr 0.61 | ms/batch 10.71 | loss  3.93 | ppl    50.84\n",
      "| epoch  41 |  2600/ 2981 batches | lr 0.61 | ms/batch 10.69 | loss  3.97 | ppl    52.90\n",
      "| epoch  41 |  2800/ 2981 batches | lr 0.61 | ms/batch 10.71 | loss  3.93 | ppl    51.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 33.22s | valid loss  5.61 | valid ppl   273.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |   200/ 2981 batches | lr 0.58 | ms/batch 10.76 | loss  4.00 | ppl    54.34\n",
      "| epoch  42 |   400/ 2981 batches | lr 0.58 | ms/batch 10.69 | loss  4.02 | ppl    55.78\n",
      "| epoch  42 |   600/ 2981 batches | lr 0.58 | ms/batch 10.69 | loss  3.87 | ppl    47.96\n",
      "| epoch  42 |   800/ 2981 batches | lr 0.58 | ms/batch 10.71 | loss  3.93 | ppl    51.00\n",
      "| epoch  42 |  1000/ 2981 batches | lr 0.58 | ms/batch 10.69 | loss  3.96 | ppl    52.29\n",
      "| epoch  42 |  1200/ 2981 batches | lr 0.58 | ms/batch 10.70 | loss  3.97 | ppl    52.92\n",
      "| epoch  42 |  1400/ 2981 batches | lr 0.58 | ms/batch 10.70 | loss  3.96 | ppl    52.42\n",
      "| epoch  42 |  1600/ 2981 batches | lr 0.58 | ms/batch 10.70 | loss  4.02 | ppl    55.47\n",
      "| epoch  42 |  1800/ 2981 batches | lr 0.58 | ms/batch 10.70 | loss  4.00 | ppl    54.65\n",
      "| epoch  42 |  2000/ 2981 batches | lr 0.58 | ms/batch 10.69 | loss  4.01 | ppl    55.24\n",
      "| epoch  42 |  2200/ 2981 batches | lr 0.58 | ms/batch 10.71 | loss  3.87 | ppl    47.81\n",
      "| epoch  42 |  2400/ 2981 batches | lr 0.58 | ms/batch 10.69 | loss  3.92 | ppl    50.40\n",
      "| epoch  42 |  2600/ 2981 batches | lr 0.58 | ms/batch 10.71 | loss  3.96 | ppl    52.33\n",
      "| epoch  42 |  2800/ 2981 batches | lr 0.58 | ms/batch 10.69 | loss  3.92 | ppl    50.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 33.25s | valid loss  5.62 | valid ppl   275.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |   200/ 2981 batches | lr 0.55 | ms/batch 10.79 | loss  3.99 | ppl    54.14\n",
      "| epoch  43 |   400/ 2981 batches | lr 0.55 | ms/batch 10.75 | loss  4.01 | ppl    55.24\n",
      "| epoch  43 |   600/ 2981 batches | lr 0.55 | ms/batch 10.73 | loss  3.86 | ppl    47.48\n",
      "| epoch  43 |   800/ 2981 batches | lr 0.55 | ms/batch 10.73 | loss  3.93 | ppl    50.75\n",
      "| epoch  43 |  1000/ 2981 batches | lr 0.55 | ms/batch 10.75 | loss  3.95 | ppl    51.78\n",
      "| epoch  43 |  1200/ 2981 batches | lr 0.55 | ms/batch 10.73 | loss  3.96 | ppl    52.65\n",
      "| epoch  43 |  1400/ 2981 batches | lr 0.55 | ms/batch 10.75 | loss  3.96 | ppl    52.35\n",
      "| epoch  43 |  1600/ 2981 batches | lr 0.55 | ms/batch 10.73 | loss  4.01 | ppl    54.89\n",
      "| epoch  43 |  1800/ 2981 batches | lr 0.55 | ms/batch 10.75 | loss  3.99 | ppl    54.05\n",
      "| epoch  43 |  2000/ 2981 batches | lr 0.55 | ms/batch 10.74 | loss  4.01 | ppl    55.24\n",
      "| epoch  43 |  2200/ 2981 batches | lr 0.55 | ms/batch 10.73 | loss  3.86 | ppl    47.60\n",
      "| epoch  43 |  2400/ 2981 batches | lr 0.55 | ms/batch 10.75 | loss  3.92 | ppl    50.37\n",
      "| epoch  43 |  2600/ 2981 batches | lr 0.55 | ms/batch 10.74 | loss  3.95 | ppl    51.70\n",
      "| epoch  43 |  2800/ 2981 batches | lr 0.55 | ms/batch 10.75 | loss  3.91 | ppl    50.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 33.36s | valid loss  5.61 | valid ppl   271.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |   200/ 2981 batches | lr 0.52 | ms/batch 10.81 | loss  3.98 | ppl    53.59\n",
      "| epoch  44 |   400/ 2981 batches | lr 0.52 | ms/batch 10.73 | loss  4.01 | ppl    55.13\n",
      "| epoch  44 |   600/ 2981 batches | lr 0.52 | ms/batch 10.74 | loss  3.86 | ppl    47.34\n",
      "| epoch  44 |   800/ 2981 batches | lr 0.52 | ms/batch 10.73 | loss  3.92 | ppl    50.52\n",
      "| epoch  44 |  1000/ 2981 batches | lr 0.52 | ms/batch 10.75 | loss  3.94 | ppl    51.48\n",
      "| epoch  44 |  1200/ 2981 batches | lr 0.52 | ms/batch 10.73 | loss  3.96 | ppl    52.39\n",
      "| epoch  44 |  1400/ 2981 batches | lr 0.52 | ms/batch 10.73 | loss  3.95 | ppl    52.02\n",
      "| epoch  44 |  1600/ 2981 batches | lr 0.52 | ms/batch 10.75 | loss  3.99 | ppl    54.27\n",
      "| epoch  44 |  1800/ 2981 batches | lr 0.52 | ms/batch 10.73 | loss  3.98 | ppl    53.68\n",
      "| epoch  44 |  2000/ 2981 batches | lr 0.52 | ms/batch 10.75 | loss  4.00 | ppl    54.57\n",
      "| epoch  44 |  2200/ 2981 batches | lr 0.52 | ms/batch 10.74 | loss  3.86 | ppl    47.24\n",
      "| epoch  44 |  2400/ 2981 batches | lr 0.52 | ms/batch 10.75 | loss  3.91 | ppl    49.89\n",
      "| epoch  44 |  2600/ 2981 batches | lr 0.52 | ms/batch 10.74 | loss  3.94 | ppl    51.55\n",
      "| epoch  44 |  2800/ 2981 batches | lr 0.52 | ms/batch 10.73 | loss  3.91 | ppl    49.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 33.36s | valid loss  5.61 | valid ppl   273.78\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  45 |   200/ 2981 batches | lr 0.50 | ms/batch 10.80 | loss  3.97 | ppl    53.20\n",
      "| epoch  45 |   400/ 2981 batches | lr 0.50 | ms/batch 10.75 | loss  4.00 | ppl    54.45\n",
      "| epoch  45 |   600/ 2981 batches | lr 0.50 | ms/batch 10.73 | loss  3.85 | ppl    46.86\n",
      "| epoch  45 |   800/ 2981 batches | lr 0.50 | ms/batch 10.75 | loss  3.91 | ppl    50.06\n",
      "| epoch  45 |  1000/ 2981 batches | lr 0.50 | ms/batch 10.74 | loss  3.94 | ppl    51.20\n",
      "| epoch  45 |  1200/ 2981 batches | lr 0.50 | ms/batch 10.75 | loss  3.95 | ppl    51.85\n",
      "| epoch  45 |  1400/ 2981 batches | lr 0.50 | ms/batch 10.74 | loss  3.95 | ppl    51.80\n",
      "| epoch  45 |  1600/ 2981 batches | lr 0.50 | ms/batch 10.74 | loss  3.99 | ppl    54.11\n",
      "| epoch  45 |  1800/ 2981 batches | lr 0.50 | ms/batch 10.76 | loss  3.98 | ppl    53.67\n",
      "| epoch  45 |  2000/ 2981 batches | lr 0.50 | ms/batch 10.73 | loss  3.99 | ppl    54.25\n",
      "| epoch  45 |  2200/ 2981 batches | lr 0.50 | ms/batch 10.75 | loss  3.85 | ppl    46.77\n",
      "| epoch  45 |  2400/ 2981 batches | lr 0.50 | ms/batch 10.74 | loss  3.90 | ppl    49.44\n",
      "| epoch  45 |  2600/ 2981 batches | lr 0.50 | ms/batch 10.75 | loss  3.93 | ppl    51.06\n",
      "| epoch  45 |  2800/ 2981 batches | lr 0.50 | ms/batch 10.77 | loss  3.90 | ppl    49.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 33.40s | valid loss  5.61 | valid ppl   274.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |   200/ 2981 batches | lr 0.47 | ms/batch 10.82 | loss  3.97 | ppl    53.01\n",
      "| epoch  46 |   400/ 2981 batches | lr 0.47 | ms/batch 10.76 | loss  4.00 | ppl    54.45\n",
      "| epoch  46 |   600/ 2981 batches | lr 0.47 | ms/batch 10.78 | loss  3.85 | ppl    46.79\n",
      "| epoch  46 |   800/ 2981 batches | lr 0.47 | ms/batch 10.77 | loss  3.91 | ppl    49.72\n",
      "| epoch  46 |  1000/ 2981 batches | lr 0.47 | ms/batch 10.78 | loss  3.93 | ppl    50.99\n",
      "| epoch  46 |  1200/ 2981 batches | lr 0.47 | ms/batch 10.77 | loss  3.94 | ppl    51.62\n",
      "| epoch  46 |  1400/ 2981 batches | lr 0.47 | ms/batch 10.78 | loss  3.94 | ppl    51.34\n",
      "| epoch  46 |  1600/ 2981 batches | lr 0.47 | ms/batch 10.77 | loss  3.98 | ppl    53.70\n",
      "| epoch  46 |  1800/ 2981 batches | lr 0.47 | ms/batch 10.77 | loss  3.97 | ppl    53.17\n",
      "| epoch  46 |  2000/ 2981 batches | lr 0.47 | ms/batch 10.78 | loss  3.99 | ppl    54.08\n",
      "| epoch  46 |  2200/ 2981 batches | lr 0.47 | ms/batch 10.77 | loss  3.84 | ppl    46.57\n",
      "| epoch  46 |  2400/ 2981 batches | lr 0.47 | ms/batch 10.79 | loss  3.90 | ppl    49.38\n",
      "| epoch  46 |  2600/ 2981 batches | lr 0.47 | ms/batch 10.77 | loss  3.93 | ppl    50.93\n",
      "| epoch  46 |  2800/ 2981 batches | lr 0.47 | ms/batch 10.78 | loss  3.89 | ppl    49.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 33.47s | valid loss  5.61 | valid ppl   273.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |   200/ 2981 batches | lr 0.45 | ms/batch 10.83 | loss  3.97 | ppl    52.73\n",
      "| epoch  47 |   400/ 2981 batches | lr 0.45 | ms/batch 10.77 | loss  3.98 | ppl    53.77\n",
      "| epoch  47 |   600/ 2981 batches | lr 0.45 | ms/batch 10.79 | loss  3.84 | ppl    46.50\n",
      "| epoch  47 |   800/ 2981 batches | lr 0.45 | ms/batch 10.77 | loss  3.90 | ppl    49.44\n",
      "| epoch  47 |  1000/ 2981 batches | lr 0.45 | ms/batch 10.77 | loss  3.92 | ppl    50.61\n",
      "| epoch  47 |  1200/ 2981 batches | lr 0.45 | ms/batch 10.78 | loss  3.94 | ppl    51.31\n",
      "| epoch  47 |  1400/ 2981 batches | lr 0.45 | ms/batch 10.77 | loss  3.94 | ppl    51.40\n",
      "| epoch  47 |  1600/ 2981 batches | lr 0.45 | ms/batch 10.78 | loss  3.98 | ppl    53.37\n",
      "| epoch  47 |  1800/ 2981 batches | lr 0.45 | ms/batch 10.77 | loss  3.96 | ppl    52.62\n",
      "| epoch  47 |  2000/ 2981 batches | lr 0.45 | ms/batch 10.78 | loss  3.98 | ppl    53.62\n",
      "| epoch  47 |  2200/ 2981 batches | lr 0.45 | ms/batch 10.77 | loss  3.84 | ppl    46.30\n",
      "| epoch  47 |  2400/ 2981 batches | lr 0.45 | ms/batch 10.77 | loss  3.89 | ppl    49.06\n",
      "| epoch  47 |  2600/ 2981 batches | lr 0.45 | ms/batch 10.78 | loss  3.93 | ppl    50.76\n",
      "| epoch  47 |  2800/ 2981 batches | lr 0.45 | ms/batch 10.77 | loss  3.89 | ppl    49.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 33.48s | valid loss  5.61 | valid ppl   272.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |   200/ 2981 batches | lr 0.43 | ms/batch 10.82 | loss  3.96 | ppl    52.43\n",
      "| epoch  48 |   400/ 2981 batches | lr 0.43 | ms/batch 10.78 | loss  3.97 | ppl    53.24\n",
      "| epoch  48 |   600/ 2981 batches | lr 0.43 | ms/batch 10.77 | loss  3.84 | ppl    46.36\n",
      "| epoch  48 |   800/ 2981 batches | lr 0.43 | ms/batch 10.78 | loss  3.90 | ppl    49.23\n",
      "| epoch  48 |  1000/ 2981 batches | lr 0.43 | ms/batch 10.77 | loss  3.92 | ppl    50.30\n",
      "| epoch  48 |  1200/ 2981 batches | lr 0.43 | ms/batch 10.76 | loss  3.93 | ppl    51.04\n",
      "| epoch  48 |  1400/ 2981 batches | lr 0.43 | ms/batch 10.77 | loss  3.93 | ppl    50.89\n",
      "| epoch  48 |  1600/ 2981 batches | lr 0.43 | ms/batch 10.76 | loss  3.98 | ppl    53.43\n",
      "| epoch  48 |  1800/ 2981 batches | lr 0.43 | ms/batch 10.74 | loss  3.96 | ppl    52.69\n",
      "| epoch  48 |  2000/ 2981 batches | lr 0.43 | ms/batch 10.69 | loss  3.98 | ppl    53.33\n",
      "| epoch  48 |  2200/ 2981 batches | lr 0.43 | ms/batch 10.70 | loss  3.83 | ppl    46.00\n",
      "| epoch  48 |  2400/ 2981 batches | lr 0.43 | ms/batch 10.69 | loss  3.89 | ppl    48.69\n",
      "| epoch  48 |  2600/ 2981 batches | lr 0.43 | ms/batch 10.69 | loss  3.92 | ppl    50.28\n",
      "| epoch  48 |  2800/ 2981 batches | lr 0.43 | ms/batch 10.71 | loss  3.89 | ppl    48.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 33.34s | valid loss  5.63 | valid ppl   277.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |   200/ 2981 batches | lr 0.40 | ms/batch 10.76 | loss  3.95 | ppl    52.11\n",
      "| epoch  49 |   400/ 2981 batches | lr 0.40 | ms/batch 10.69 | loss  3.98 | ppl    53.43\n",
      "| epoch  49 |   600/ 2981 batches | lr 0.40 | ms/batch 10.71 | loss  3.83 | ppl    46.02\n",
      "| epoch  49 |   800/ 2981 batches | lr 0.40 | ms/batch 10.69 | loss  3.89 | ppl    48.95\n",
      "| epoch  49 |  1000/ 2981 batches | lr 0.40 | ms/batch 10.71 | loss  3.92 | ppl    50.24\n",
      "| epoch  49 |  1200/ 2981 batches | lr 0.40 | ms/batch 10.70 | loss  3.93 | ppl    50.87\n",
      "| epoch  49 |  1400/ 2981 batches | lr 0.40 | ms/batch 10.69 | loss  3.92 | ppl    50.54\n",
      "| epoch  49 |  1600/ 2981 batches | lr 0.40 | ms/batch 10.71 | loss  3.97 | ppl    52.99\n",
      "| epoch  49 |  1800/ 2981 batches | lr 0.40 | ms/batch 10.70 | loss  3.96 | ppl    52.41\n",
      "| epoch  49 |  2000/ 2981 batches | lr 0.40 | ms/batch 10.71 | loss  3.98 | ppl    53.42\n",
      "| epoch  49 |  2200/ 2981 batches | lr 0.40 | ms/batch 10.69 | loss  3.82 | ppl    45.83\n",
      "| epoch  49 |  2400/ 2981 batches | lr 0.40 | ms/batch 10.71 | loss  3.88 | ppl    48.38\n",
      "| epoch  49 |  2600/ 2981 batches | lr 0.40 | ms/batch 10.69 | loss  3.92 | ppl    50.19\n",
      "| epoch  49 |  2800/ 2981 batches | lr 0.40 | ms/batch 10.69 | loss  3.88 | ppl    48.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 33.23s | valid loss  5.61 | valid ppl   273.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |   200/ 2981 batches | lr 0.38 | ms/batch 10.76 | loss  3.95 | ppl    52.04\n",
      "| epoch  50 |   400/ 2981 batches | lr 0.38 | ms/batch 10.75 | loss  3.97 | ppl    52.79\n",
      "| epoch  50 |   600/ 2981 batches | lr 0.38 | ms/batch 10.73 | loss  3.83 | ppl    45.91\n",
      "| epoch  50 |   800/ 2981 batches | lr 0.38 | ms/batch 10.74 | loss  3.89 | ppl    48.82\n",
      "| epoch  50 |  1000/ 2981 batches | lr 0.38 | ms/batch 10.73 | loss  3.91 | ppl    49.72\n",
      "| epoch  50 |  1200/ 2981 batches | lr 0.38 | ms/batch 10.75 | loss  3.93 | ppl    50.66\n",
      "| epoch  50 |  1400/ 2981 batches | lr 0.38 | ms/batch 10.73 | loss  3.92 | ppl    50.47\n",
      "| epoch  50 |  1600/ 2981 batches | lr 0.38 | ms/batch 10.73 | loss  3.97 | ppl    52.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  50 |  1800/ 2981 batches | lr 0.38 | ms/batch 10.75 | loss  3.96 | ppl    52.29\n",
      "| epoch  50 |  2000/ 2981 batches | lr 0.38 | ms/batch 10.73 | loss  3.97 | ppl    52.79\n",
      "| epoch  50 |  2200/ 2981 batches | lr 0.38 | ms/batch 10.75 | loss  3.82 | ppl    45.77\n",
      "| epoch  50 |  2400/ 2981 batches | lr 0.38 | ms/batch 10.73 | loss  3.87 | ppl    48.10\n",
      "| epoch  50 |  2600/ 2981 batches | lr 0.38 | ms/batch 10.75 | loss  3.91 | ppl    49.93\n",
      "| epoch  50 |  2800/ 2981 batches | lr 0.38 | ms/batch 10.73 | loss  3.88 | ppl    48.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 33.35s | valid loss  5.63 | valid ppl   279.85\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(TEXT.vocab.stoi)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "        # prevent explosion.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    ntokens = len(TEXT.vocab.stoi)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output = eval_model(data)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)\n",
    "\n",
    "\n",
    "ntokens = len(TEXT.vocab.stoi) # the size of vocabulary\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
    "\n",
    "bptt = 35\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 50 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "        print('Saved best model at', epoch)\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  5.56 | test ppl   259.32\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text\n",
    "\n",
    "Tried to generate text which follows one of text picked from test data, for N words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(text):\n",
    "    return np.array([' '.join([TEXT.vocab.itos[i] for i in text[:, k]]) for k in range(text.size(1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Starting from: <eos> = robert <unk> = <eos> <eos> robert <unk> is an english film , television and theatre actor . he had a guest @-@ starring role on the television series the bill in 2000 .\n",
      "Generated: <eos> = = = = = = = = <eos> <eos> <eos> <eos> = = = = = = = = = = = = = = = = = = = = <eos> <eos> <eos> the first was born in the first son of the first son of aralt\n",
      "[1]\n",
      "Starting from: = robert <unk> = <eos> <eos> robert <unk> is an english film , television and theatre actor . he had a guest @-@ starring role on the television series the bill in 2000 . this\n",
      "Generated: episode was written by david carpenter , who was a guest star game , who was a comedy series of the series of the series of the series of the series of the series of the series . <eos> = = = = = = = = <eos> <eos> <eos>\n",
      "[2]\n",
      "Starting from: robert <unk> = <eos> <eos> robert <unk> is an english film , television and theatre actor . he had a guest @-@ starring role on the television series the bill in 2000 . this was\n",
      "Generated: a comedy series of the film was written by patrick ewing , sam perkins , chris brown , chris brown , chris brown , chris brown , chris brown , who was a <unk> , who was a <unk> , who was a <unk> , and <unk> . <eos> =\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def generate_text(start_text, N):\n",
    "    query_text = copy.deepcopy(start_text)\n",
    "    generated = torch.zeros((N, 1), dtype=torch.long)\n",
    "    for i in range(N):\n",
    "        o = best_model(query_text)\n",
    "        generated[i, 0] = o.argmax(-1)[-1, 0]\n",
    "        query_text = query_text.roll(-1)\n",
    "        query_text[-1, 0] = generated[i, 0]\n",
    "        #print(decompose(ref))\n",
    "    return generated\n",
    "\n",
    "\n",
    "for idx in range(3):\n",
    "    N = 50\n",
    "    ref = get_batch(test_data, idx)[0][:, :1]\n",
    "    generated = generate_text(ref, N)\n",
    "    print(f'[{idx}]')\n",
    "    print('Starting from:', decompose(ref)[0])\n",
    "    print('Generated:', decompose(generated)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "Starting from: He was born\n",
      "Generated: in the <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and <unk> , and\n"
     ]
    }
   ],
   "source": [
    "inputs = 'He was born'\n",
    "\n",
    "tokens = [TEXT.vocab.stoi[w.lower()] for w in inputs.split()]\n",
    "tensor_tokens = torch.Tensor(tokens).to(torch.long).to(device).unsqueeze(-1)\n",
    "print(tensor_tokens.shape)\n",
    "generated = generate_text(tensor_tokens, N)\n",
    "print('Starting from:', inputs)\n",
    "print('Generated:', decompose(generated)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
